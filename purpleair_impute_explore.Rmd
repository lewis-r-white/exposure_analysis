---
title: "PurpleAir Imputation"
output: html_document
date: "2025-05-01"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load libraries, include=FALSE}
# load libraries 
library(tidyverse)
library(purrr)
library(lubridate)
library(tidyr)
library(sf)
library(here)
library(readxl)

library(performance)
library(lme4)
library(ICC)
library(broom)
library(modelr)
library(viridis)

# ML packages 
library(tidymodels)
library(tictoc)
library(vip)
library(patchwork)
library(doParallel)
library(xgboost)
library(glmnet)
library(mgcv)
library(yardstick) 
library(furrr)
library(future)
```


# Load datasets

```{R load datasets, include = FALSE}


# PURPLE AIR ----
purpleair_community_r3 <- readRDS(here("exposure_data", "purpleair_community_r3.rds")) 

purpleair <- purpleair_community_r3 %>%
  mutate(community_id = toupper(community_id),
         
         community_id = case_when(
           community_id == "GUESTHOUSE 1" ~ "GUESTHOUSE",
           community_id == "GUESTHOUSE 2" ~ "GUESTHOUSE",
           TRUE ~ community_id),
         
         # make sure timestamp right format
         timestamp = ymd_hms(timestamp),
        
         # add date
         date = date(timestamp))





## PERSONAL EXPOSURE ----

upas <- read.csv(here("exposure_data", "upasr3_communities.csv")) %>%
  distinct(subject_id, .keep_all = TRUE)
                 
upas_df <- readRDS(here("exposure_data", "upasr3_rawPMrt.rds"))

upas_as_dataframe <- function(sublist) {
  df <- as.data.frame(sublist)
  

  if (!inherits(df$DateTimeLocal, "POSIXct")) {
    df$DateTimeLocal <- as.POSIXct(df$DateTimeLocal, format = "%Y-%m-%d %H:%M:%S", tz = "GMT")
  }
  
  return(df)
}



upas_df <- do.call(rbind, lapply(upas_df, upas_as_dataframe)) %>% #join all the personal exposure data sets together
  
  # join 30 second personal exposure data to summarized personal exposure data 
  left_join(upas %>% dplyr::select(subject_id, community, compliance_hours, run_time_hour, start_time, end_time), by = "subject_id") %>%  
  
  mutate(PM2_5MC = as.numeric(PM2_5MC)) %>% # convert pm reading to numeric 
  
  filter(PM2_5MC >= 5 & PM2_5MC <= 800) # filter pm reading to plausible values

```

# clean data / look into irregular interval data recording and remove bad data

```{r}
# Compute time difference between rows within each community + date
bad_intervals <- purpleair %>%
  arrange(community_id, timestamp) %>%
  group_by(community_id, date) %>%
  mutate(dt = as.numeric(difftime(timestamp, lag(timestamp), units = "secs"))) %>%
  summarise(median_dt = median(dt, na.rm = TRUE),
            n_obs = n(),
            .groups = "drop") %>%
  filter(median_dt < 60)  # i.e., faster than every minute

purpleair_clean <- purpleair %>%
  anti_join(bad_intervals, by = c("community_id", "date"))
```

# assess data completeness 

## personal monitor completeness 
```{r}
upas_personal_hourly <- upas_df %>%
  mutate(hourly_time = floor_date(DateTimeLocal, unit = "hours")) %>%
  group_by(subject_id, hourly_time) %>%
  summarize(n_obs = n(), 
            mean_pm25 = mean(PM2_5MC),
            .groups = "drop") %>%
  
  # remove times when there isn't 75% of data in the hour
  filter(n_obs > 90)

upas_personal_hourly %>%
  count(subject_id, name = "n_hours") %>%
  ggplot(aes(x = n_hours)) +
  geom_histogram(binwidth = 5, fill = "steelblue", color = "white", boundary = 0) +
  labs(
    title = "Distribution of Personal Exposure Monitoring Hours per Subject",
    x = "Number of Valid Hours",
    y = "Number of Subjects"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(hjust = 0.5),
    panel.grid.minor = element_blank()
  )



upas_community_hourly <- upas_df %>%
  mutate(hourly_time = floor_date(DateTimeLocal, unit = "hours")) %>%
  group_by(community, hourly_time) %>%
  summarize(n_obs = n(), .groups = "drop") %>%
  
  # remove times when there isn't 75% of data in the hour
  filter(n_obs > 90)


ggplot(upas_community_hourly, aes(x = hourly_time, y = community)) +
  geom_point(alpha = 0.2) +
  labs(title = "Data availability by community over time",
       x = "Time (Hourly)",
       y = "Community") +
  theme_minimal()

```

# purpleair completeness
```{r}
## USING PM DATA ----
# Count rows per community-date
daily_counts <- purpleair_clean %>%
  filter(!is.na(pm2_5_atm_final)) %>%
  count(community_id, date, name = "n_obs") %>%
  mutate(pct_complete = n_obs / 720)

# filter to days with at least 75% completeness
daily_good <- daily_counts %>% filter(pct_complete >= 0.75)

ggplot(daily_counts, aes(x = date, y = community_id, fill = pct_complete)) +
  geom_tile(color = "white") +
  scale_fill_viridis_c(name = "Daily completeness", limits = c(0, 1)) +
  labs(title = "PurpleAir Data Completeness by Community",
       x = "Date", y = "Community") +
  theme_minimal()




## TRY FOR WEAHTER DATA INSTEAD ---- 
# Count rows per community-date
daily_counts_rh <- purpleair_clean %>%
  filter(!is.na(current_humidity)) %>%
  count(community_id, date, name = "n_obs") %>%
  mutate(pct_complete = n_obs / 720)

# filter to days with at least 75% completeness
daily_good_rh <- daily_counts %>% filter(pct_complete >= 0.75)

ggplot(daily_counts_rh, aes(x = date, y = community_id, fill = pct_complete)) +
  geom_tile(color = "white") +
  scale_fill_viridis_c(name = "Daily completeness", limits = c(0, 1)) +
  labs(title = "PurpleAir Data Completeness by Community",
       x = "Date", y = "Community") +
  theme_minimal()
```

data completeness is baddddd. 


```{r}
# Aggregate purpleair data to hourly
purpleair_hourly <- purpleair_clean %>%
  mutate(timestamp = floor_date(timestamp, "hour")) %>%
  filter(!is.na(pm2_5_atm_final)) %>%
  group_by(community_id, timestamp) %>%
  filter(n() >= 22) %>%  # Keep only groups with at least 22 observations
  summarize(
    pm2_5 = mean(pm2_5_atm_final),
    temp = mean(current_temp_f),
    rh = mean(current_humidity),
    dew = mean(current_dewpoint_f),
    .groups = "drop"
  ) %>%
  mutate(
    hour = hour(timestamp),
    month = month(timestamp),
    dow = wday(timestamp),
    date = as.Date(timestamp)
  )


purpleair_hourly %>% ggplot(aes(x = pm2_5)) +
  geom_histogram(binwidth = 25, fill = "steelblue", color = "white", boundary = 0) +
  labs(
    title = "Distribution of Personal Exposure Monitoring",
    x = "PM 2.5 Measurement",
    y = "Number of Hours"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(hjust = 0.5),
    panel.grid.minor = element_blank()
  )


purpleair_hourly %>% 
  filter(pm2_5 < 200) %>%
  ggplot(aes(x = pm2_5)) +
  geom_histogram(binwidth = 10, fill = "steelblue", color = "white", boundary = 0) +
  labs(
    title = "Distribution of Personal Exposure Monitoring",
    x = "PM 2.5 Measurement",
    y = "Number of Hours"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(hjust = 0.5),
    panel.grid.minor = element_blank()
  )
```


# Investigate data irregularities (extremely low average PM2.5, dew point/temp)

```{r}
pa_hourly_explore_anomalies <- purpleair_hourly %>%
  mutate(low_pm = ifelse(pm2_5 < 6, 1, 0)) %>%
  mutate(temp_below_dew = ifelse(temp < dew, 1, 0)) %>%
  mutate(year = year(date))

## TESTING IF TEMP BELOW DEW IS CAUSING LOW READINGS ----
pa_hourly_explore_anomalies %>% filter(temp_below_dew == 1) # just two obs. both suspiciously high dew. 

# Also tried temp < dew + 1 and number of obs remained low. 
# CONCLUSION: UNLIKELY TEMP BELOW DEW CUASING WIDESPREAD MONITOR ISSUES 


pa_hourly_explore_anomalies %>%
  mutate(low_pm_label = ifelse(low_pm == 1, "PM < 6", "PM > 6")) %>%
  ggplot(aes(y = dew)) +
  geom_boxplot() +
  labs(x = "Hourly PM Value",
       y = "Dew Point",
       title = "Distribution of Dew Point for PM 2.5 Groupings",
       subtitle = "Dew Point Temperature Trends Higher for Lower PM 2.5 Readings") +
  facet_wrap(~low_pm_label) +
  theme_bw() +
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  ) 

pa_hourly_explore_anomalies %>%
  mutate(low_pm_label = ifelse(low_pm == 1, "PM < 6", "PM > 6")) %>%
  ggplot(aes(y = rh)) +
  geom_boxplot() +
  labs(x = "Hourly PM Value",
       y = "Relative Humidity",
       title = "Distribution of Relative Humidity for PM 2.5 Groupings",
       subtitle = "Relative Humidity Trends Higher for Lower PM 2.5 Readings") +
  facet_wrap(~low_pm_label) +
  theme_bw() +
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  ) 

pa_hourly_explore_anomalies %>%
  mutate(low_pm_label = ifelse(low_pm == 1, "PM < 6", "PM > 6")) %>%
  ggplot(aes(y = temp)) +
  geom_boxplot() +
  labs(x = "Hourly PM Value",
       y = "Temperature",
       title = "Distribution of Temperature for PM 2.5 Groupings",
       subtitle = "Temperature Distributions Appear Similar") +
  facet_wrap(~low_pm_label) +
  theme_bw() +
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  ) 

low_pm_by_community <- pa_hourly_explore_anomalies %>%
  group_by(community_id, low_pm) %>%
  summarise(n = n(), .groups = "drop") %>%
  pivot_wider(names_from = low_pm, values_from = n, values_fill = 0) %>%
  rename(pm_above_6 = `0`, pm_below_6 = `1`) %>%
  mutate(total = pm_above_6 + pm_below_6,
         prop_low_pm = pm_below_6 / total)

low_pm_by_community %>%
  ggplot(aes(x = reorder(community_id, -prop_low_pm), y = prop_low_pm)) +
  geom_col(fill = "steelblue4") +
  coord_flip() +
  labs(
    x = "Community",
    y = "Proportion of PM < 6 Readings",
    title = "Proportion of Low PM Readings by Community"
  ) +
  theme_minimal()



pa_hourly_explore_anomalies %>%
  mutate(month = floor_date(date, "month")) %>%
  group_by(community_id, month, low_pm) %>%
  summarise(n = n(), .groups = "drop") %>%
  pivot_wider(names_from = low_pm, values_from = n, values_fill = 0) %>%
  rename(pm_above_6 = `0`, pm_below_6 = `1`) %>%
  mutate(total = pm_above_6 + pm_below_6,
         prop_low_pm = pm_below_6 / total) %>%
  ggplot(aes(x = month, y = reorder(community_id, -prop_low_pm), fill = prop_low_pm)) +
  geom_tile(color = "white") +
  scale_fill_viridis_c(name = "Prop. PM < 6", limits = c(0, 1)) +
  labs(
    x = "Month",
    y = "Community",
    title = "Proportion of Low PM2.5 Readings (<6) by Community and Month"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


weila <- pa_hourly_explore_anomalies %>% filter(community_id == "WEILA") # section of all 0s. Need to be removed. 
akora <- pa_hourly_explore_anomalies %>% filter(community_id == "AKORA") # all seem suspicious. harmattan season should have much higher readings 

kunsu <- pa_hourly_explore_anomalies %>% filter(community_id == "KUNSU") 
kunsu_full <- purpleair_clean %>% filter(community_id == "KUNSU") 

ajena <- pa_hourly_explore_anomalies %>% filter(community_id == "AJENA") 
ajena_full <- purpleair_clean %>% filter(community_id == "AJENA") 

## LOOKS LIKE THERE ARE ISSUES WITH THE SENSORS 
```


## box plots of hourly pm 2.5 for communities 

```{r}
median_order <- purpleair_hourly %>%
  group_by(community_id) %>%
  summarise(median_pm = median(pm2_5, na.rm = TRUE)) %>%
  arrange(median_pm) %>%
  pull(community_id)

purpleair_hourly_ordered <- purpleair_hourly %>%
  mutate(community_id = factor(community_id, levels = median_order)) %>%
  filter(pm2_5 < 150) # few values. removing for visualization purposes

ggplot(purpleair_hourly_ordered, aes(x = community_id, y = pm2_5)) +
  geom_boxplot(outlier.size = 0.5, outlier.alpha = 0.3) +
  coord_flip() +  # Flip axes for readability
  labs(title = "PM2.5 Distribution by Community",
       x = "Community",
       y = "PM2.5 (µg/m³)") +
  theme_minimal()

```


## correlation matrix of monitors 

```{r}
library(tidyverse)
library(corrplot)
library(ggcorrplot)


# Pivot to wide format
pm_wide <- purpleair_hourly %>%
  filter(pm2_5 > 7) %>%
  select(timestamp, community_id, pm2_5) %>%
  pivot_wider(names_from = community_id, values_from = pm2_5)

# Remove constant or all-NA columns
pm_wide_filtered <- pm_wide %>%
  select(-timestamp) %>%
  select(where(~ sd(., na.rm = TRUE) > 0 & sum(!is.na(.)) >= 100))  # also enforce 100+ obs

# Correlation matrix
cor_matrix <- cor(pm_wide_filtered, use = "pairwise.complete.obs")

# Pairwise complete observations
overlap_matrix <- outer(
  colnames(pm_wide_filtered), colnames(pm_wide_filtered),
  Vectorize(function(x, y) sum(complete.cases(pm_wide_filtered[[x]], pm_wide_filtered[[y]])))
)

rownames(overlap_matrix) <- colnames(overlap_matrix) <- colnames(pm_wide_filtered)

# Mask correlations with < 100 overlaps
cor_matrix[overlap_matrix < 100] <- NA

ggcorrplot(cor_matrix,
           type = "lower",
           lab = TRUE,
           lab_size = 2.5,
           colors = c("blue", "white", "red"),
           outline.color = "gray") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

## SOME SUSPICIOUS PERFECT CORRELATIONS AND NEGATIVE CORRELATIONS... FURTHER INVESTIGATION BELOW.

# Pick two communities
scatter_df <- pm_wide %>%
  select(timestamp, DWENEWOHO, `JATO AKURA`) %>%
  filter(!is.na(DWENEWOHO) & !is.na(`JATO AKURA`))  # Only overlapping times

# Plot
ggplot(scatter_df, aes(x = DWENEWOHO, y = `JATO AKURA`)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "PM2.5: DWENEWOHO vs `JATO AKURA`",
       x = "DWENEWOHO PM2.5",
       y = "``JATO AKURA` PM2.5") +
  theme_minimal()

```



# Mean of other monitors for imputation ----

```{r}
purpleair_hourly_fleet_avg <- purpleair_hourly %>%
  group_by(timestamp) %>%
  mutate(
    n_reporting = sum(!is.na(pm2_5)),  # total non-missing PM2.5 at that hour
    fleet_avg_pm2_5 = ifelse(
      !is.na(pm2_5) & n_reporting > 1,
      (sum(pm2_5, na.rm = TRUE) - pm2_5) / (n_reporting - 1),
      ifelse(n_reporting > 0, sum(pm2_5, na.rm = TRUE) / n_reporting, NA)
      )
  ) %>%
  ungroup() %>%
  filter(n_reporting >= 1) # could adjust if want to ensure fleet average included a minimum number of monitors 


## CHECK METRICS 

# Filter only rows where both actual and predicted values are available
fleet_eval <- purpleair_hourly_fleet_avg %>%
  filter(!is.na(pm2_5), !is.na(fleet_avg_pm2_5))

# Evaluate performance
fleet_metrics <- metrics(fleet_eval, truth = pm2_5, estimate = fleet_avg_pm2_5)
print(fleet_metrics)

#  .metric .estimator .estimate
#   <chr>   <chr>          <dbl>
# 1 rmse    standard      19.6  
# 2 rsq     standard       0.525
# 3 mae     standard      10.5  

ggplot(fleet_eval, aes(x = pm2_5, y = fleet_avg_pm2_5)) +
  geom_point(alpha = 0.3) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(
    title = "Fleet Average: Observed vs. Predicted PM2.5",
    x = "Observed PM2.5",
    y = "Fleet Average PM2.5 (Predicted)"
  ) +
  theme_minimal()
```


# Elastic Net Regression ----

### split data into training and test sets and set up cross validation

```{r}
purpleair_hourly_fleet_avg_clean <- purpleair_hourly_fleet_avg %>%
  mutate(harmattan = month %in% c(12, 1, 2)) %>%
  filter(if_all(c(temp, rh, dew), ~ !is.na(.))) 

set.seed(123)
split_enet <- initial_split(purpleair_hourly_fleet_avg_clean, prop = 0.8)
train_enet <- training(split_enet)
test_enet <- testing(split_enet)


#set up cross validation 
cv_folds_enet <- vfold_cv(train_enet, v = 5)
```

### create preprocessing recipe

```{r}
recipe_enet <- recipe(pm2_5 ~ fleet_avg_pm2_5 + n_reporting + hour + harmattan + dow + temp + rh + dew, data = train_enet) %>%
  step_mutate(
    hour = as.factor(hour),
    harmattan = as.factor(harmattan),
    dow = as.factor(dow)
  ) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
  step_normalize(all_numeric_predictors())
```

### create model specifications and workflow 
```{r}
spec_enet <- linear_reg(penalty = tune(), 
                        mixture = tune()) %>%
  set_mode("regression") %>%
  set_engine("glmnet")


wf_enet <- workflow() %>%
  add_recipe(recipe_enet) %>%
  add_model(spec_enet)
```

### tune hyperparamets 

```{r}
grid_enet <- grid_regular(
  penalty(range = c(-4, 0)),   # 10^-4 to 10^0
  mixture(range = c(0, 1)),    # Ridge to Lasso
  levels = 5
)

registerDoParallel()

tuned_enet <- tune_grid(
  wf_enet,
  resamples = cv_folds_enet,
  grid = grid_enet,
  metrics = metric_set(rmse, rsq, mae)
)

```


### select best parameters and finalize model 

```{r}
best_enet <- select_best(tuned_enet, metric = "rmse")

final_wf_enet <- finalize_workflow(wf_enet, best_enet)

final_fit_enet <- last_fit(final_wf_enet, split_enet)

collect_metrics(final_fit_enet)

#   .metric .estimator .estimate .config             
#   <chr>   <chr>          <dbl> <chr>               
# 1 rmse    standard      18.8   Preprocessor1_Model1
# 2 rsq     standard       0.563 Preprocessor1_Model1
```

### Fit to full data 

```{r}
final_model_enet <- fit(final_wf_enet, data = train_enet)

# Predict on test data (or full dataset)
test_predictions_enet <- predict(final_model_enet, new_data = test_enet) %>%
  bind_cols(test_enet)

# Plot observed vs. predicted
ggplot(test_predictions_enet, aes(x = pm2_5, y = .pred)) +
  geom_point(alpha = 0.4) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(title = "Elastic Net: Observed vs Predicted PM2.5 (Test Set)",
       x = "Observed",
       y = "Predicted") +
  theme_minimal()
```



# GAM Approach ----



### split data into training and test sets and set up cross validation

```{r}
purpleair_hourly_fleet_avg_clean <- purpleair_hourly_fleet_avg %>%
  mutate(harmattan = month %in% c(12, 1, 2)) %>%
  filter(if_all(c(temp, rh, dew), ~ !is.na(.))) 

set.seed(123)
split_gam <- initial_split(purpleair_hourly_fleet_avg_clean, prop = 0.8)
train_gam <- training(split_gam) %>%
  mutate(
    hour = as.numeric(hour),
    harmattan = as.factor(harmattan),
    dow = as.factor(dow)
  )


test_gam <- testing(split_gam) %>%
  mutate(
    hour = as.numeric(hour),
    harmattan = as.factor(harmattan),
    dow = as.factor(dow)
  )



# Define GAM formula
gam_formula <- pm2_5 ~ 
  s(fleet_avg_pm2_5) +
  s(temp) +
  s(rh) +
  s(dew) +
  s(hour, bs = "cc", k = 24) +
  s(n_reporting) +
  harmattan +
  dow

# Fit the GAM directly
gam_model <- gam(
  formula = gam_formula,
  data = train_gam,
  method = "REML",
  select = TRUE,  # enables variable selection (shrinkage)
  gamma = 1       # smoothness adjustment; default = 1
)


test_gam$predicted_pm <- predict(gam_model, newdata = test_gam)

test_metrics_gam <- test_gam %>%
  filter(!is.na(pm2_5), !is.na(predicted_pm)) %>%
  metrics(truth = pm2_5, estimate = predicted_pm)

print(test_metrics_gam)

# 1 rmse    standard      18.3  
# 2 rsq     standard       0.582
# 3 mae     standard      10.2  

ggplot(test_gam, aes(x = pm2_5, y = predicted_pm)) +
  geom_point(alpha = 0.4) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  theme_minimal() +
  labs(title = "GAM (mgcv): Observed vs Predicted PM2.5 (Test Set)")


```


# XG BOOST to impute missing data ----

## Option 1: given lack of data, just use weather vars 

### split data into training and test sets and set up cross validation

```{r}
set.seed(123)
split <- initial_split(purpleair_hourly, prop = 0.8) # tried stratifying by community but not enough data
train <- training(split)
test <- testing(split)


#set up cross validation 
cv_folds <- vfold_cv(train, v = 5)

```

### create preprocessing recipe
```{r}
pa_recipe <- recipe(pm2_5 ~ community_id + hour + month + dow + temp + rh + dew, data = train) %>%
  step_mutate(
    hour = as.factor(hour),
    month = as.factor(month),
    dow = as.factor(dow)
  ) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
  step_normalize(all_numeric_predictors())
```


### XGBoost model specification 
```{r}
xgb_spec <- boost_tree(
  trees = 1000,
  tree_depth = tune(),
  learn_rate = tune(),
  loss_reduction = tune(),
  sample_size = tune(),
  mtry = tune()
) %>%
  set_mode("regression") %>%
  set_engine("xgboost")

```

### tune the model 
```{r}
xgb_grid <- grid_max_entropy(
  tree_depth(),
  learn_rate(),
  loss_reduction(),
  sample_prop(),
  finalize(mtry(), train),
  size = 20
)

xgb_wf <- workflow() %>%
  add_recipe(pa_recipe) %>%
  add_model(xgb_spec)

registerDoParallel()
set.seed(123)

xgb_tuned <- tune_grid(
  xgb_wf,
  resamples = cv_folds,
  grid = xgb_grid,
  metrics = metric_set(rmse, rsq, mae)
)

```


### finalize workflow and evaluate on test set

```{r}
best_params <- select_best(xgb_tuned, metric = "rmse")

final_wf <- finalize_workflow(xgb_wf, best_params)

final_fit <- last_fit(final_wf, split)

collect_metrics(final_fit)

```


### fit to all data and predict missing 2021

```{r}
# Fit to all available data
final_model <- fit(final_wf, data = data_model)

# Predict 2021 community-hour rows with missing pm2_5
to_impute <- purpleair_hourly %>%
  filter(is.na(pm2_5))

imputed <- predict(final_model, new_data = to_impute) %>%
  bind_cols(to_impute)

```




### make predictions on full dataset

```{r}
# Fit final model on full training set
final_model <- fit(final_wf, data = train)

# Predict on full data (train + test or just test if you prefer)
purpleair_hourly <- purpleair_hourly %>%
  mutate(predicted_pm = predict(final_model, new_data = purpleair_hourly)$.pred)


# plot observed vs expected 
ggplot(purpleair_hourly, aes(x = pm2_5, y = predicted_pm)) +
  geom_point(alpha = 0.3) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(title = "Observed vs. Predicted PM2.5",
       x = "Observed PM2.5",
       y = "Predicted PM2.5") +
  theme_minimal()


# visualize errors by community
purpleair_hourly <- purpleair_hourly %>%
  mutate(error = pm2_5 - predicted_pm)

error_summary <- purpleair_hourly %>%
  group_by(community_id) %>%
  summarize(rmse = sqrt(mean(error^2, na.rm = TRUE)),
            mae = mean(abs(error), na.rm = TRUE),
            rsq = cor(pm2_5, predicted_pm, use = "complete.obs")^2)

# Barplot of RMSE by community
ggplot(error_summary, aes(x = reorder(community_id, rmse), y = rmse)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "RMSE by Community",
       x = "Community",
       y = "RMSE (µg/m³)") +
  theme_minimal()
```

### Test variable importance 

```{r}
# Bake the training data using the recipe from your workflow
baked_train <- prep(pa_recipe) %>%
  bake(new_data = train)

# Extract final tuned parameters
final_model_spec <- boost_tree(
  trees = 1000,
  learn_rate = best_params$learn_rate,
  tree_depth = best_params$tree_depth,
  loss_reduction = best_params$loss_reduction,
  sample_size = best_params$sample_size,
  mtry = best_params$mtry
) %>%
  set_engine("xgboost") %>%
  set_mode("regression")

# Fit model directly
xgb_fit <- fit(final_model_spec, pm2_5 ~ ., data = baked_train)


vip(xgb_fit, num_features = 20, geom = "col") +
  labs(title = "Top 20 Variable Importances from XGBoost Model")

```


## option 2: use fleet average in model and interact with communities 

```{r}
purpleair_hourly_fleet_avg <- purpleair_hourly %>%
  group_by(timestamp) %>%
  mutate(
    n_reporting = sum(!is.na(pm2_5)),  # total non-missing PM2.5 at that hour
    fleet_avg_pm2_5 = ifelse(
      !is.na(pm2_5) & n_reporting > 1,
      (sum(pm2_5, na.rm = TRUE) - pm2_5) / (n_reporting - 1),
      ifelse(n_reporting > 0, sum(pm2_5, na.rm = TRUE) / n_reporting, NA)
      )
  ) %>%
  ungroup() %>%
  filter(n_reporting >= 3)
```


### split data into training and test sets and set up cross validation

```{r}
set.seed(123)
split <- initial_split(purpleair_hourly_fleet_avg, prop = 0.8) # tried stratifying by community but not enough data
train <- training(split)
test <- testing(split)


#set up cross validation 
cv_folds <- vfold_cv(train, v = 5)

```

### create preprocessing recipe
```{r}
pa_recipe <- recipe(pm2_5 ~ fleet_avg_pm2_5 + community_id + hour + month + dow + temp + rh + dew, data = train) %>%
  step_mutate(
    hour = as.factor(hour),
    month = as.factor(month),
    dow = as.factor(dow)
  ) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_interact(terms = ~ starts_with("community_id"):fleet_avg_pm2_5) # interaction between community and fleet average

```


### XGBoost model specification 
```{r}
xgb_spec <- boost_tree(
  trees = 1000,
  tree_depth = tune(),
  learn_rate = tune(),
  loss_reduction = tune(),
  sample_size = tune(),
  mtry = tune()
) %>%
  set_mode("regression") %>%
  set_engine("xgboost")

```

### tune the model 
```{r}
xgb_grid <- grid_max_entropy(
  tree_depth(),
  learn_rate(),
  loss_reduction(),
  sample_prop(),
  finalize(mtry(), train),
  size = 20
)

xgb_wf <- workflow() %>%
  add_recipe(pa_recipe) %>%
  add_model(xgb_spec)

tictoc::tic()

registerDoParallel()
set.seed(123)

xgb_tuned <- tune_grid(
  xgb_wf,
  resamples = cv_folds,
  grid = xgb_grid,
  metrics = metric_set(rmse, rsq, mae)
)

tictoc::toc() # 48 mins
beepr::beep(sound = 2)
```


### finalize workflow and evaluate on test set

```{r}
best_params <- select_best(xgb_tuned, metric = "rmse")

final_wf <- finalize_workflow(xgb_wf, best_params)

final_fit <- last_fit(final_wf, split)

collect_metrics(final_fit)
          
#   .metric .estimator .estimate .config             
#   <chr>   <chr>          <dbl> <chr>               
# 1 rmse    standard       9.81  Preprocessor1_Model1
# 2 rsq     standard       0.878 Preprocessor1_Model1
```


### Evaluate model performance on test set

```{r}
model_test_eval <- fit(final_wf, data = train)

test_results <- test %>%
  mutate(predicted_pm = predict(model_test_eval, new_data = test)$.pred) %>%
  mutate(error = pm2_5 - predicted_pm)

# Observed vs predicted
ggplot(test_results, aes(x = pm2_5, y = predicted_pm)) +
  geom_point(alpha = 0.3) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(title = "XGBoost: Observed vs. Predicted PM2.5 (Test Set)",
       x = "Observed PM2.5",
       y = "Predicted PM2.5") +
  theme_minimal()

# Error by community
error_summary_test <- test_results %>%
  group_by(community_id) %>%
  summarise(
    rmse = sqrt(mean(error^2, na.rm = TRUE)),
    mae = mean(abs(error), na.rm = TRUE),
    rsq = cor(pm2_5, predicted_pm, use = "complete.obs")^2,
    n = n()
  )

# Barplot of RMSE by community (test set)
ggplot(error_summary_test, aes(x = reorder(community_id, rmse), y = rmse)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "XGBoost: RMSE by Community (Test Set)",
       x = "Community",
       y = "RMSE (µg/m³)") +
  theme_minimal()
```


### Fit and evaluate model on full dataset (in-sample)

```{r}
# Fit final model on full training set
final_model <- fit(final_wf, data = purpleair_hourly_fleet_avg)

# Predict on full data
purpleair_hourly_fleet_avg <- purpleair_hourly_fleet_avg %>%
  mutate(predicted_pm = predict(final_model, new_data = purpleair_hourly_fleet_avg)$.pred)


# plot observed vs expected 
ggplot(purpleair_hourly_fleet_avg, aes(x = pm2_5, y = predicted_pm)) +
  geom_point(alpha = 0.3) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(
  title = "XGBoost with Fleet Avg: In-Sample Fit on Full Dataset",
  x = "Observed PM2.5",
  y = "Predicted PM2.5"
) +
  theme_minimal()


# visualize errors by community
purpleair_hourly_fleet_avg <- purpleair_hourly_fleet_avg %>%
  mutate(error = pm2_5 - predicted_pm)

error_summary <- purpleair_hourly_fleet_avg %>%
  group_by(community_id) %>%
  summarize(rmse = sqrt(mean(error^2, na.rm = TRUE)),
            mae = mean(abs(error), na.rm = TRUE),
            rsq = cor(pm2_5, predicted_pm, use = "complete.obs")^2)

# Barplot of RMSE by community
ggplot(error_summary, aes(x = reorder(community_id, rmse), y = rmse)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(
  title = "XGBoost In-Sample RMSE by Community (Full Dataset)",
  x = "Community",
  y = "RMSE (µg/m³)"
) +
  theme_minimal()
```

### Variable importance from final model (training data only)

```{r}
# Bake the training data using the recipe from your workflow
baked_train <- prep(pa_recipe) %>%
  bake(new_data = train)

# Extract final tuned parameters
final_model_spec <- boost_tree(
  trees = 1000,
  learn_rate = best_params$learn_rate,
  tree_depth = best_params$tree_depth,
  loss_reduction = best_params$loss_reduction,
  sample_size = best_params$sample_size,
  mtry = best_params$mtry
) %>%
  set_engine("xgboost") %>%
  set_mode("regression")

# Fit model directly
xgb_fit <- fit(final_model_spec, pm2_5 ~ ., data = baked_train)


vip(xgb_fit, num_features = 20, geom = "col") +
  labs(title = "Top 20 Variable Importances from XGBoost Model")

```


## option 3: using individual communities pm25 as columns 

```{r}
purpleair_wide <- purpleair_hourly %>%
  dplyr::select(timestamp, community_id, pm2_5) %>%
  pivot_wider(names_from = community_id, values_from = pm2_5, names_prefix = "pm2_5_")

purpleair_model_data <- purpleair_hourly %>%
  left_join(purpleair_wide, by = "timestamp") %>%
  filter(!is.na(pm2_5))  # Keep only rows with observed PM2.5 (target)

# # remove the target community's own PM2.5 column to prevent leakage
# purpleair_model_data <- purpleair_model_data %>%
#   rowwise() %>%
#   mutate(across(starts_with("pm2_5_"), ~ if_else(cur_column() == paste0("pm2_5_", community_id), NA_real_, .x))) %>%
#   ungroup()


# Create a column with the name of the predictor to blank
purpleair_model_data <- purpleair_model_data %>%
  mutate(target_column = paste0("pm2_5_", community_id))

# Get the column names of all wide-format PM2.5 predictors
pm_cols <- grep("^pm2_5_", names(purpleair_model_data), value = TRUE)

# Blank out the target community column in one shot
for (col in pm_cols) {
  purpleair_model_data[[col]] <- ifelse(
    purpleair_model_data$target_column == col,
    NA_real_,
    purpleair_model_data[[col]]
  )
}
```

### split data into training and test sets and set up cross validation

```{r}
set.seed(123)
split_xgb_all_coms <- initial_split(purpleair_model_data, prop = 0.8) # tried stratifying by community but not enough data
train_xgb_all_coms <- training(split_xgb_all_coms)
test_xgb_all_coms <- testing(split_xgb_all_coms)

#set up cross validation 
cv_folds_xgb_all_coms<- vfold_cv(train_xgb_all_coms, v = 5)
```

### pre-processing recipe

```{r}
all_pm_cols <- grep("^pm2_5_", names(purpleair_model_data), value = TRUE)

recipe_xgb_all_coms <- recipe(pm2_5 ~ ., data = purpleair_model_data) %>%
  update_role(timestamp, new_role = "ID") %>%
  update_role(date, new_role = "ID") %>%  
  step_mutate(
    hour = as.factor(hour),
    month = as.factor(month),
    dow = as.factor(dow)
  ) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
  step_normalize(all_numeric_predictors())

```


### XGBoost model specification 
```{r}
spec_xgb_all_coms <- boost_tree(
  trees = 1000,
  tree_depth = tune(),
  learn_rate = tune(),
  loss_reduction = tune(),
  sample_size = tune(),
  mtry = tune()) %>%
  set_mode("regression") %>%
  set_engine("xgboost")
```

### tune the model 
```{r}
grid_xgb_all_coms <- grid_max_entropy(
  tree_depth(),
  learn_rate(),
  loss_reduction(),
  sample_prop(),
  finalize(mtry(), train),
  size = 20
)

wf_xgb_all_coms <- workflow() %>%
  add_recipe(recipe_xgb_all_coms) %>%
  add_model(spec_xgb_all_coms)

tictoc::tic()

registerDoParallel()
set.seed(123)

tuned_xgb_all_coms <- tune_grid(
  wf_xgb_all_coms,
  resamples = cv_folds_xgb_all_coms,
  grid = grid_xgb_all_coms,
  metrics = metric_set(rmse, rsq, mae)
)

tictoc::toc()
beepr::beep(sound = 2) # toook an hour and five mins
```


### finalize workflow and evaluate on test set

```{r}
best_params_xgb_all_coms <- select_best(tuned_xgb_all_coms, metric = "rmse")

final_wf_xgb_all_coms <- finalize_workflow(wf_xgb_all_coms, best_params_xgb_all_coms)

final_fit_xgb_all_coms <- last_fit(final_wf_xgb_all_coms, split_xgb_all_coms)

collect_metrics(final_fit_xgb_all_coms) 
# rmse    standard       8.53  Preprocessor1_Model1
# rsq     standard       0.913 Preprocessor1_Model1
```


### Evaluate model performance on test set

```{r}
model_test_eval_xgb_all_coms <- fit(final_wf_xgb_all_coms, data = train_xgb_all_coms)

test_results_xgb_all_coms <- test_xgb_all_coms %>%
  mutate(predicted_pm = predict(model_test_eval_xgb_all_coms, new_data = test_xgb_all_coms)$.pred) %>%
  mutate(error = pm2_5 - predicted_pm)

# Observed vs predicted
ggplot(test_results_xgb_all_coms, aes(x = pm2_5, y = predicted_pm)) +
  geom_point(alpha = 0.3) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(title = "XGBoost All Monitors: Observed vs. Predicted PM2.5 (Test Set)",
       x = "Observed PM2.5",
       y = "Predicted PM2.5") +
  theme_minimal()

# Error by community
error_summary_test_xgb_all_coms <- test_results_xgb_all_coms %>%
  group_by(community_id) %>%
  summarise(
    rmse = sqrt(mean(error^2, na.rm = TRUE)),
    mae = mean(abs(error), na.rm = TRUE),
    rsq = cor(pm2_5, predicted_pm, use = "complete.obs")^2,
    n = n()
  )

# Barplot of RMSE by community (test set)
ggplot(error_summary_test_xgb_all_coms, aes(x = reorder(community_id, rmse), y = rmse)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "XGBoost All Monitors: RMSE by Community (Test Set)",
       x = "Community",
       y = "RMSE (µg/m³)") +
  theme_minimal()
```


### Fit and evaluate model on full dataset (in-sample)

```{r}
# Fit final model on full training set
final_model_xgb_all_coms <- fit(final_wf_xgb_all_coms, data = purpleair_model_data)

# Predict on full data
purpleair_model_data_xgb_all_coms <- purpleair_model_data %>%
  mutate(predicted_pm = predict(final_model_xgb_all_coms, new_data = purpleair_model_data)$.pred)


# plot observed vs expected 
ggplot(purpleair_model_data_xgb_all_coms, aes(x = pm2_5, y = predicted_pm)) +
  geom_point(alpha = 0.3) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(title = "XG Boost All Monitors: In-Sample Fit Full Dataset",
       x = "Observed PM2.5",
       y = "Predicted PM2.5") +
  theme_minimal()


# visualize errors by community
purpleair_model_data_xgb_all_coms <- purpleair_model_data_xgb_all_coms %>%
  mutate(error = pm2_5 - predicted_pm)

error_summary_xgb_all_coms <- purpleair_model_data_xgb_all_coms %>%
  group_by(community_id) %>%
  summarize(rmse = sqrt(mean(error^2, na.rm = TRUE)),
            mae = mean(abs(error), na.rm = TRUE),
            rsq = cor(pm2_5, predicted_pm, use = "complete.obs")^2)

# Barplot of RMSE by community
ggplot(error_summary_xgb_all_coms, aes(x = reorder(community_id, rmse), y = rmse)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "XG Boost In-Sample RMSE by Community",
       x = "Community",
       y = "RMSE (µg/m³)") +
  theme_minimal()
```

### Testing on just pre-2022 data 

```{r}
early_period_eval_xgb_all_coms <- purpleair_model_data_xgb_all_coms %>%
  filter(date < as.Date("2022-01-01")) %>%
  filter(!is.na(pm2_5), !is.na(predicted_pm)) %>%
  metrics(truth = pm2_5, estimate = predicted_pm)

print(early_period_eval_xgb_all_coms)


## METRICS BY COMMUNITY

# Filter to early sparse period
early_data_xgb_all_coms <- purpleair_model_data_xgb_all_coms %>%
  filter(date < as.Date("2022-01-01")) %>%
  filter(!is.na(pm2_5), !is.na(predicted_pm))

ggplot(early_data_xgb_all_coms, aes(x = pm2_5, y = predicted_pm)) +
  geom_point(alpha = 0.3) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(title = "Observed vs. Predicted PM2.5 (Pre-2022)",
       x = "Observed PM2.5",
       y = "Predicted PM2.5") +
  theme_minimal()

# Calculate metrics by community
early_metrics_by_community_xgb_all_coms <- early_data_xgb_all_coms %>%
  group_by(community_id) %>%
  summarise(
    rmse = sqrt(mean((pm2_5 - predicted_pm)^2, na.rm = TRUE)),
    mae = mean(abs(pm2_5 - predicted_pm), na.rm = TRUE),
    rsq = cor(pm2_5, predicted_pm, use = "complete.obs")^2,
    n = n()
  ) %>%
  arrange(desc(n))


ggplot(early_metrics_by_community_xgb_all_coms, aes(x = reorder(community_id, rmse), y = rmse)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "RMSE by Community (Before 2022)",
       x = "Community",
       y = "RMSE (µg/m³)") +
  theme_minimal()
```


## Predicting for the full dataset to get a sense of completeness 

```{r}
timestamps <- unique(purpleair_hourly$timestamp)
communities <- unique(purpleair_hourly$community_id)

full_grid <- expand_grid(timestamp = timestamps, community_id = communities)

#Add predictors (weather/time vars, wide-format monitor data)
imputation_data <- full_grid %>%
  left_join(purpleair_hourly, by = c("timestamp", "community_id")) %>%
  left_join(purpleair_wide, by = "timestamp") %>%
  mutate(target_column = paste0("pm2_5_", community_id))


# Prepare the full prediction dataset (repeat target-blanking step)
pm_cols <- grep("^pm2_5_", names(imputation_data), value = TRUE)

for (col in pm_cols) {
  imputation_data[[col]] <- ifelse(
    imputation_data$target_column == col,
    NA_real_,
    imputation_data[[col]]
  )
}

# Train the model on all observed data
final_model_xgb_all_coms <- fit(final_wf_xgb_all_coms, data = purpleair_model_data)

# Apply your model to full data (using the same recipe)
predicted_all <- predict(final_model_xgb_all_coms, new_data = imputation_data)

# Add to dataframe
prediction_data <- imputation_data %>%
  bind_cols(predicted_all) %>%
  rename(predicted_pm2_5 = .pred)

# Use predicted value only where pm2_5 is NA
prediction_data_filled <- prediction_data %>%
  mutate(pm2_5_filled = if_else(is.na(pm2_5), predicted_pm2_5, pm2_5))



## CHECK OUT COMPLETENESS OF PREDICTIONS
prediction_completeness <- prediction_data_filled %>%
  mutate(date = as.Date(timestamp)) %>%
  group_by(community_id, date) %>%
  summarise(n_obs = sum(!is.na(pm2_5_filled)), .groups = "drop") %>%
  mutate(pct_complete = n_obs / 24)  # 24 hours expected per day

# plot completeness after prediction
ggplot(prediction_completeness, aes(x = date, y = community_id, fill = pct_complete)) +
  geom_tile(color = "white", linewidth = 0.1) +
  scale_fill_viridis_c(name = "Daily completeness", limits = c(0, 1)) +
  labs(title = "Daily PM 2.5 Completeness After Imputation",
       subtitle = "Based on predicted or observed values",
       x = "Date", y = "Community") +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 6))

```


# Random Forests 
Using network of communities did not work for RF. Struggled with missing values and computation time too long. 

```{r}
purpleair_hourly_fleet_avg <- purpleair_hourly %>%
  group_by(timestamp) %>%
  mutate(
    n_reporting = sum(!is.na(pm2_5)),  # total non-missing PM2.5 at that hour
    fleet_avg_pm2_5 = ifelse(
      !is.na(pm2_5) & n_reporting > 1,
      (sum(pm2_5, na.rm = TRUE) - pm2_5) / (n_reporting - 1),
      ifelse(n_reporting > 0, sum(pm2_5, na.rm = TRUE) / n_reporting, NA)
      )
  ) %>%
  ungroup() %>%
  filter(n_reporting >= 3)
```


### split data into training and test sets and set up cross validation

```{r}
set.seed(123)

split <- initial_split(purpleair_hourly_fleet_avg, prop = 0.8) # tried stratifying by community but not enough data
train <- training(split)
test <- testing(split)

#set up cross validation 
cv_folds <- vfold_cv(train, v = 5)

```



### pre-processing recipe

```{r}
rf_recipe_multi <- recipe(pm2_5 ~ fleet_avg_pm2_5 + temp + rh + dew + hour + month + dow, data = purpleair_hourly_fleet_avg) %>%
  step_mutate(
    hour = as.factor(hour),
    month = as.factor(month),
    dow = as.factor(dow)
  ) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE)


```


### random forest model specification 
```{r}
rf_spec <- rand_forest(
  mtry = tune(),
  min_n = tune(),
  trees = 100
) %>%
  set_mode("regression") %>%
  set_engine("ranger")

```

### tune the model 
```{r}
rf_grid <- grid_regular(
  finalize(mtry(), train),  # adapts mtry to number of predictors
  min_n(range = c(2, 20)),
  levels = 5
)
```


### finalize workflow and evaluate on test set

```{r}
rf_wf <- workflow() %>%
  add_recipe(rf_recipe_multi) %>%
  add_model(rf_spec)

library(ranger)

library(doParallel)
cl <- makeCluster(4)
registerDoParallel(cl)

rf_tuned <- tune_grid(
  rf_wf,
  resamples = cv_folds,
  grid = rf_grid,
  metrics = metric_set(rmse, rsq, mae),
  control = control_grid(verbose = TRUE)
)

stopCluster(cl)


best_rf <- select_best(rf_tuned, "rmse")

final_rf_wf <- finalize_workflow(rf_wf, best_rf)

final_rf_fit <- last_fit(final_rf_wf, split)

collect_metrics(final_rf_fit)

# # A tibble: 2 × 4
#   .metric .estimator .estimate .config             
#   <chr>   <chr>          <dbl> <chr>               
# 1 rmse    standard      13.1   Preprocessor1_Model1
# 2 rsq     standard       0.781 Preprocessor1_Model1
```



### make predictions on full dataset

```{r}
rf_final_model <- fit(final_rf_wf, data = train)

purpleair_hourly_fleet_avg <- purpleair_hourly_fleet_avg %>%
  mutate(predicted_pm = predict(rf_final_model, new_data = purpleair_hourly_fleet_avg)$.pred)



ggplot(purpleair_hourly_fleet_avg, aes(x = pm2_5, y = predicted_pm)) +
  geom_point(alpha = 0.3) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(title = "Random Forest: Observed vs. Predicted PM2.5",
       x = "Observed PM2.5",
       y = "Predicted PM2.5") +
  theme_minimal()


# Compute residuals
purpleair_hourly_fleet_avg <- purpleair_hourly_fleet_avg %>%
  mutate(error = pm2_5 - predicted_pm)

# Summarize RMSE, MAE, R² by community
error_summary <- purpleair_hourly_fleet_avg %>%
  group_by(community_id) %>%
  summarize(
    rmse = sqrt(mean(error^2, na.rm = TRUE)),
    mae = mean(abs(error), na.rm = TRUE),
    rsq = cor(pm2_5, predicted_pm, use = "complete.obs")^2,
    n = n()
  )

# Barplot of RMSE by community
ggplot(error_summary, aes(x = reorder(community_id, rmse), y = rmse)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Random Forest: RMSE by Community",
       x = "Community",
       y = "RMSE (µg/m³)") +
  theme_minimal()

```

### Evaluate on pre-2022 data 

```{r}
early_period_eval <- purpleair_hourly_fleet_avg %>%
  filter(date < as.Date("2022-01-01")) %>%
  filter(!is.na(pm2_5), !is.na(predicted_pm)) %>%
  metrics(truth = pm2_5, estimate = predicted_pm)

print(early_period_eval)

#   .metric .estimator .estimate
#   <chr>   <chr>          <dbl>
# 1 rmse    standard       5.33 
# 2 rsq     standard       0.888
# 3 mae     standard       3.14 

early_data <- purpleair_hourly_fleet_avg %>%
  filter(date < as.Date("2022-01-01")) %>%
  filter(!is.na(pm2_5), !is.na(predicted_pm))


ggplot(early_data, aes(x = pm2_5, y = predicted_pm)) +
  geom_point(alpha = 0.3) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(title = "Observed vs. Predicted PM2.5 (Pre-2022)",
       x = "Observed PM2.5",
       y = "Predicted PM2.5") +
  theme_minimal()


early_metrics_by_community <- early_data %>%
  group_by(community_id) %>%
  summarise(
    rmse = sqrt(mean((pm2_5 - predicted_pm)^2, na.rm = TRUE)),
    mae = mean(abs(pm2_5 - predicted_pm), na.rm = TRUE),
    rsq = cor(pm2_5, predicted_pm, use = "complete.obs")^2,
    n = n()
  ) %>%
  arrange(desc(n))

# Plot early period RMSE by community
ggplot(early_metrics_by_community, aes(x = reorder(community_id, rmse), y = rmse)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Random Forest: RMSE by Community (Before 2022)",
       x = "Community",
       y = "RMSE (µg/m³)") +
  theme_minimal()

```



# Copy Mean

```{r}
library(longitudinalData) # for imputation()
```

