---
title: "UPAS Processing"
date: "`r Sys.Date()`"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

### Load Dependancies

library(ggplot2)
library(plotly)
library(scales)
library(lubridate)
library(data.table)
library(gridExtra)
library(cowplot)
library(plyr)
library(dplyr)
library(grid)
library(zoo)
library(openxlsx)
library(beanplot)
library(readr)
library(htmlwidgets)
library(leaflet)
library(readxl)
library(xts)
library(dygraphs)
library(ggdist) #for half-density plots
library(dplyr)
library(tidyr)
library(stringr)
library(gt)
library(gtsummary)
library(astr)
library(ggpubr)
library(data.table)
library(here)

```

## Getting Started
Update `path`, `community`, and `date` for your weekly folder.
Hit "run all" to generate:
An `.rds` file of cleaned raw data
A summary `.csv` for QC review
A color-coded `.xlsx` for QC review


## Load path to specific folder containing txt files to be read and cleaned

```{r,echo = FALSE}

##Import raw UPAS files. This should be folder containing the txt files. 
path <- "/Users/lewiswhite/CHAP_columbia/GRAPHS/exposure_analysis/weekly_data_checks/upas_data2025/weekly_report_data/AJENA_UPAS_DATA_20251105"

file_upas <- list.files(path, pattern = "*.txt", full.names = F,recursive = TRUE)

length(file_upas) # check to make sure data is there

# specify meta data (pull this from file name)
date = "20251105"
community = "ajena"
```


## Specify column names of interest
```{r, echo = FALSE}
#Previous UPAS Firmware (Prior to May 2025)

#118 columns
upas_colnames <- c("SampleTime","UnixTime", "UnixTimeMCU","DateTimeUTC","DateTimeLocal","PumpingFlowRate" ,"OverallFlowRate","SampledVolume" , "FilterDP" ,                "BatteryCharge","AtmoT","AtmoP","AtmoRH","AtmoDensity","AtmoAlt","GPSQual","GPSlat","GPSlon","GPSalt","GPSsat" ,"GPSspeed","GPShDOP","AccelX" , "AccelXVar",               
"AccelXMin","AccelXMax","AccelY","AccelYVar","AccelYMin","AccelYMax","AccelZ","AccelZVar","AccelZMin","AccelZMax","RotX" ,"RotXVar" , "RotXMin","RotXMax","RotY",             "RotYVar" , "RotYMin","RotYMax", "RotZ" ,"RotZVar","RotZMin","RotZMax","AccelComplianceCnt","AccelComplianceHrs","Xup", "XDown", "Yup","Ydown","Zup","Zdown",                 "StepCount", "LUX","UVindex","HighVisRaw","LowVisRaw","IRRaw","UVRaw","PMMeasCnt","PM1MC","PM1MCVar","PM2_5MC","PM2_5MCVar","PM4MC" ,"PM4MCVar","PM10MC","PM10MCVar", "PM0_5NC", "PM0_5NCVar","PM1NC","PM1NCVar","PM2_5NC", "PM2_5NCVar","PM4NC","PM4NCVar","PM10NC","PM10NCVar","PMtypicalParticleSize","PMtypicalParticleSizeVar", "PM2_5SampledMass" ,"PMReadingErrorCnt","PMFanErrorCnt","PMLaserErrorCnt","PMFanSpeedWarn","PCB1T","PCB2T","FdpT","AccelT","PT100R","PCB2P", "PumpPow1","PumpPow2", "PumpV","MassFlow","MFSVout","BFGenergy","BattVolt","v3_3","v5","PumpsON","Dead","BCS1" , "BCS2","BC_NPG","FLOWCTL","GPSRT","SD_DATAW","SD_HEADW",                 "TPumpsOFF","TPumpsON","CO2" ,"SCDT","SCDRH","VOCRaw","NOXRaw"
)


```

## Helper function to define segment second intervals 

```{r}
# ---- shared helper: derive_seg_sec ----
# This function estimates the sampling interval between consecutive timestamps. It calculates time differences in seconds, replaces missing or invalid values with a sensible default (based on the median interval or device PMSensorInterval), and caps unusually large gaps to one nominal step to yield a stable, step-size vector.


derive_seg_sec <- function(ts_posix, pmsi = NA) {
  # ts_posix: POSIXct time vector (or something coercible)
  # pmsi: device PMSensorInterval (can be char like "30", "30 sec", etc.)
  t <- suppressWarnings(as.numeric(ts_posix))
  d <- c(NA_real_, diff(t))

  # 1) try median positive diff
  step_med <- suppressWarnings(stats::median(d[is.finite(d) & d > 0], na.rm = TRUE))

  # 2) fallback to PMSensorInterval (1..600 s), else 30
  if (!is.finite(step_med)) {
    step_guess <- suppressWarnings(readr::parse_number(pmsi[1]))
    if (!is.finite(step_guess) || step_guess < 1 || step_guess > 600) step_guess <- 30
    step_med <- step_guess
  }

  # credit rules
  d[1] <- step_med                    # first row gets the nominal step
  d[!is.finite(d) | d < 0] <- 0       # NA/negative diffs -> 0 credit
  d[d > 5 * step_med] <- step_med     # cap absurd gaps at 1 step

  # safety: ensure correct length
  if (length(d) != length(t)) d <- rep(step_med, length(t))
  d
}

```


## function to load data before may 2025
```{r,echo = FALSE,warning = FALSE, message = FALSE}
# #Firmware Prior to May 2025 
# function_read_UPAS_data <- function(filepath) {
#   
#   data_parameter  <- read.csv(filepath, header = F, nrows = 76, skip = 1)
#   colnames(data_parameter) <- c("PARAMETER","VALUE","UNITS.NOTES")
#   
#   data_raw  <- read_csv(file = filepath, skip = 117, skip_empty_rows = T, col_names = FALSE,locale = readr::locale(encoding = encoding$encoding), guess_max = 10000, show_col_types = FALSE)
# 
#   problems <- problems(data_raw)
#   bad_rows <- problems$row
#   # print(bad_rows)
#   
#   colnames(data_raw) <- upas_colnames
#   # names <- data_raw[1,]
#   
#   # data_raw$badrows <- nrow(problems)
#   if(length(bad_rows) > 0){
#      data_raw <- data_raw[-c(bad_rows), ]
#     
#   }
# 
#   
#   data <- data_raw %>%
#     dplyr::mutate(
#            UPASserial = subset(data_parameter, PARAMETER == "UPASserial")$VALUE[1],
#            SampleName = subset(data_parameter, PARAMETER == "SampleName")$VALUE[1],
#            CartridgeID = subset(data_parameter, PARAMETER == "CartridgeID")$VALUE[1],
#            LifetimeSampleCount = subset(data_parameter, PARAMETER == "LifetimeSampleCount")$VALUE[1],
#            
#            LifetimeSampleRuntime = subset(data_parameter, PARAMETER == "LifetimeSampleRuntime")$VALUE[1],
#            LifetimeBatteryRuntime = subset(data_parameter, PARAMETER == "LifetimeBatteryRuntime")$VALUE[1],
#            LifetimeSamplePumptime = subset(data_parameter, PARAMETER == "LifetimeSamplePumptime")$VALUE[1],
#            
#            SampledVolume = readr::parse_number(subset(data_parameter, PARAMETER == "SampledVolumeOffset")$VALUE[1]),
#            
#            OverallDuration = subset(data_parameter, PARAMETER == "OverallDuration")$VALUE[1],
#            PumpingDuration = subset(data_parameter, PARAMETER == "PumpingDuration")$VALUE[1],
#            StartBatteryCharge = subset(data_parameter, PARAMETER == "StartBatteryCharge")$VALUE[1],
#            EndBatteryCharge = subset(data_parameter, PARAMETER == "EndBatteryCharge")$VALUE[1],
#            StartBatteryVoltage = subset(data_parameter, PARAMETER == "StartBatteryVoltage")$VALUE[1],
#            EndBatteryVoltage = subset(data_parameter, PARAMETER == "EndBatteryVoltage")$VALUE[1],
#            ShutdownMode = subset(data_parameter, PARAMETER == "ShutdownMode")$VALUE[1],
#            DutyCycle  = subset(data_parameter, PARAMETER == "FlowDutyCycle")$VALUE[1],
#            UPAS_Compliance = subset(data_parameter, PARAMETER == "PercentTimeWorn")$VALUE[1],
#            ShutdownMode = subset(data_parameter, PARAMETER == "ShutdownMode")$VALUE[1]  ,
#            PMSensorInterval = subset(data_parameter, PARAMETER == "PMSensorInterval")$VALUE[1] ,
#            FlowOffset = subset(data_parameter, PARAMETER == "FlowOffset")$VALUE[1] ,
#            compliance = ifelse((AccelXVar > 100) | (AccelYVar > 100) | (AccelZVar > 100), 1, 0))
# 
# 
#   data$compliance_rollmean <- ifelse(as.numeric(rollapply(data$compliance, width=20,  FUN = mean, align = "center", na.rm = TRUE, partial=F, fill = NA)) > 0, 1, 0)
#   
#   return(data)
# }
# 
# # ##Updated Firmware (May 2025 onward)
# # function_read_UPAS_data_ <- function(filepath) {
# #   
# #   data_parameter  <- read.csv(filepath, header = F, nrows = 83, skip = 1)
# #   colnames(data_parameter) <- c("PARAMETER","VALUE","UNITS.NOTES")
# #   
# #   data_raw  <- read_csv(file = filepath, skip = 119, skip_empty_rows = T, col_names = FALSE, guess_max = 10000, show_col_types = FALSE) #updated firmware*
# #   #Removed the following: locale = readr::locale(encoding = encoding$encoding)
# # 
# #   problems <- problems(data_raw)
# #   bad_rows <- problems$row
# #   
# #   #104 columns
# #   upas_colnames <-  read.csv(filepath, header = F, nrows = 1, skip = 117)
# #   colnames(data_raw) <- upas_colnames[1,]
# # 
# #   data_raw$badrows <- nrow(problems)
# # 
# #   data <- data_raw %>%
# #     dplyr::mutate(
# #            UPASserial = subset(data_parameter, PARAMETER == "UPASserial")$VALUE[1],
# #            SampleName = subset(data_parameter, PARAMETER == "SampleName")$VALUE[1],
# #            CartridgeID = subset(data_parameter, PARAMETER == "CartridgeID")$VALUE[1],
# #            LifetimeSampleCount = subset(data_parameter, PARAMETER == "LifetimeSampleCount")$VALUE[1],
# #            
# #            LifetimeSampleRuntime = subset(data_parameter, PARAMETER == "LifetimeSampleRuntime")$VALUE[1],
# #            LifetimeBatteryRuntime = subset(data_parameter, PARAMETER == "LifetimeBatteryRuntime")$VALUE[1],
# #            LifetimeSamplePumptime = subset(data_parameter, PARAMETER == "LifetimeSamplePumptime")$VALUE[1],
# #            
# #            SampledVolume = subset(data_parameter, PARAMETER == "SampledVolume")$VALUE[1],
# #            OverallDuration = subset(data_parameter, PARAMETER == "OverallDuration")$VALUE[1],
# #            PumpingDuration = subset(data_parameter, PARAMETER == "PumpingDuration")$VALUE[1],
# #            StartBatteryCharge = subset(data_parameter, PARAMETER == "StartBatteryCharge")$VALUE[1],
# #            EndBatteryCharge = subset(data_parameter, PARAMETER == "EndBatteryCharge")$VALUE[1],
# #            StartBatteryVoltage = subset(data_parameter, PARAMETER == "StartBatteryVoltage")$VALUE[1],
# #            EndBatteryVoltage = subset(data_parameter, PARAMETER == "EndBatteryVoltage")$VALUE[1],
# #            ShutdownMode = subset(data_parameter, PARAMETER == "ShutdownMode")$VALUE[1],
# #            DutyCycle  = subset(data_parameter, PARAMETER == "FlowDutyCycle")$VALUE[1],
# #            UPAS_Compliance = subset(data_parameter, PARAMETER == "PercentTimeWorn")$VALUE[1],
# #            ShutdownMode = subset(data_parameter, PARAMETER == "ShutdownMode")$VALUE[1]  ,
# #            PMSensorInterval = subset(data_parameter, PARAMETER == "PMSensorInterval")$VALUE[1] ,
# #            FlowOffset = subset(data_parameter, PARAMETER == "FlowOffset")$VALUE[1] ,
# #            compliance = ifelse((AccelXVar > 100) | (AccelYVar > 100) | (AccelZVar > 100), 1, 0))
# # 
# # 
# #   data$compliance_rollmean <- ifelse(as.numeric(rollapply(data$compliance, width=20,  FUN = mean, align = "center", na.rm = TRUE, partial=F, fill = NA)) > 0, 1, 0)
# #   
# #   return(data)
# # }


```

## funciton to load data after may 2025

Main UPAS file reader for standard, well-formatted logs.  

This version automatically detects file encoding, reads each section of the UPAS export (parameter block, header row, and data log), applies consistent column names, and converts data types while dropping rows with parsing issues. It then merges key metadata from the header, computes derived movement and light (LUX) features, and adds compliance indicators for quick QC and downstream analysis.
```{r,echo = FALSE,warning = FALSE, message = FALSE}

function_read_UPAS_data_ <- function(filepath) {
  # 1) Detect encoding once:  uses readr::guess_encoding() to inspect the file, selects the most likely encoding, and defaults to "UTF-8" if none is detected. This prevents character corruption when reading files from different sources.
  enc_guess <- readr::guess_encoding(filepath)
  enc <- enc_guess$encoding[1]
  if (is.na(enc))
    enc <- "UTF-8"  # safe default
  
  # 2) Parameters block (same as before, but respect encoding)
  data_parameter <- read.csv(
    filepath,
    header = FALSE,
    nrows = 83,
    skip = 1,
    fileEncoding = enc
  )
  colnames(data_parameter) <- c("PARAMETER", "VALUE", "UNITS.NOTES")
  
  # 3) Read the header row with the same encoding
  upas_colnames <- read.csv(
    filepath,
    header = FALSE,
    nrows = 1,
    skip = 117,
    fileEncoding = enc
  )
  
  # 4) Read the log body with the same encoding
  data_raw <- readr::read_csv(
    file = filepath,
    skip = 119,
    # updated firmware
    skip_empty_rows = TRUE,
    col_names = FALSE,
    guess_max = 10000,
    show_col_types = FALSE,
    locale = readr::locale(encoding = enc)  # <-- key line
  )
  
  # 5) Apply column names
  colnames(data_raw) <- upas_colnames[1, ]
  
  # 6) Let readr repair types now that encoding is correct
  data_raw <- readr::type_convert(data_raw,
                                  locale = readr::locale(encoding = enc),
                                  na = c("", "NA"))
  
  # 7)  drop rows with parse problems
  pb <- readr::problems(data_raw)
  if (nrow(pb)) {
    bad_rows <- unique(pb$row)
    data_raw <- data_raw[-bad_rows, , drop = FALSE]
  }
  
  # 8) Get head level data
  data <- data_raw %>%
    dplyr::mutate(
      UPASserial = subset(data_parameter, PARAMETER == "UPASserial")$VALUE[1],
      SampleName = subset(data_parameter, PARAMETER == "SampleName")$VALUE[1],
      UPASexpRev = subset(data_parameter, PARAMETER == "UPASexpRev")$VALUE[1],
      ## NEW ADD
      CartridgeID = subset(data_parameter, PARAMETER == "CartridgeID")$VALUE[1],
      LifetimeSampleCount = subset(data_parameter, PARAMETER == "LifetimeSampleCount")$VALUE[1],
      LifetimeSampleRuntime = subset(data_parameter, PARAMETER == "LifetimeSampleRuntime")$VALUE[1],
      LifetimeBatteryRuntime = subset(data_parameter, PARAMETER == "LifetimeBatteryRuntime")$VALUE[1],
      LifetimeSamplePumptime = subset(data_parameter, PARAMETER == "LifetimeSamplePumptime")$VALUE[1],
      SampledVolume = readr::parse_number(
        subset(data_parameter, PARAMETER == "SampledVolumeOffset")$VALUE[1]
      ),
      
      OverallDuration = subset(data_parameter, PARAMETER == "OverallDuration")$VALUE[1],
      PumpingDuration = subset(data_parameter, PARAMETER == "PumpingDuration")$VALUE[1],
      StartBatteryCharge = subset(data_parameter, PARAMETER == "StartBatteryCharge")$VALUE[1],
      EndBatteryCharge = subset(data_parameter, PARAMETER == "EndBatteryCharge")$VALUE[1],
      StartBatteryVoltage = subset(data_parameter, PARAMETER == "StartBatteryVoltage")$VALUE[1],
      EndBatteryVoltage = subset(data_parameter, PARAMETER == "EndBatteryVoltage")$VALUE[1],
      DutyCycle  = subset(data_parameter, PARAMETER == "FlowDutyCycle")$VALUE[1],
      UPAS_Compliance = subset(data_parameter, PARAMETER == "PercentTimeWorn")$VALUE[1],
      ShutdownMode = subset(data_parameter, PARAMETER == "ShutdownMode")$VALUE[1],
      PMSensorInterval = subset(data_parameter, PARAMETER == "PMSensorInterval")$VALUE[1],
      FlowOffset = subset(data_parameter, PARAMETER == "FlowOffset")$VALUE[1]
      #compliance = ifelse((AccelXVar > 100) | (AccelYVar > 100) | (AccelZVar > 100), 1, 0) ## COMMENTED OUT BECAUSE AccelComplianceCnt VARIABLES IN NEW UPAS DATA IS ALREADY THE COMPLIANCE ROLL MEAN (BELOW), SO THIS IS NO LONGER NECESSARY
    )
  
  # data$compliance_rollmean <- ifelse(
  #   as.numeric(zoo::rollapply(data$compliance, width = 20, FUN = mean,
  #                             align = "center", na.rm = TRUE, partial = FALSE, fill = NA)) > 0, 1, 0)
  
  
  
  # ---- DERIVED FEATURES (movement, LUX) ----
  # Create a unified timestamp column. Prefer DateTimeLocal, but fall back to UnixTime if needed
  ts <- suppressWarnings(lubridate::ymd_hms(data$DateTimeLocal, tz = "UTC"))
  if (all(is.na(ts)) && "UnixTime" %in% names(data)) {
    ts <- as.POSIXct(as.numeric(data$UnixTime),
                     origin = "1970-01-01",
                     tz = "UTC")
  }
  data$.__ts <- ts
  
  # Convert certain variables to numeric (some come in as char or mixed types)
  numify <- function(x)
    suppressWarnings(readr::parse_number(as.character(x)))
  for (v in c("AccelXVar",
              "AccelYVar",
              "AccelZVar",
              "AccelComplianceCnt",
              "LUX",
              "DutyCycle")) {
    if (v %in% names(data))
      data[[v]] <- numify(data[[v]])
  }
  
  # Order by timestamp and calculate a few derived fields
  # LUX_s: short (3-point) rolling median of LUX to smooth spikes
  # seg_sec: estimated sampling interval in seconds from derive_seg_sec()
  data <- data %>%
    arrange(.__ts) %>%
    mutate(
      LUX_s = zoo::rollmedian(LUX, 3, fill = NA),
      seg_sec = derive_seg_sec(.__ts, PMSensorInterval)
    )
  
  # --- Motion-based compliance -----------------------------------------
  # Convert firmware 0–20 count to proportion (0–1)
  data$AccelComplianceCnt_prop <- data$AccelComplianceCnt / 20
  
  # Boolean "worn" indicator directly from firmware logic
  data$worn_flag <- as.integer(data$AccelComplianceCnt > 0)
  
  # Combine X/Y/Z acceleration variance into one magnitude measure
  # (used mainly for quick QC checks / plots)
  if (all(c("AccelXVar", "AccelYVar", "AccelZVar") %in% names(data))) {
  data$acc_mag <- rowSums(cbind(data$AccelXVar, data$AccelYVar, data$AccelZVar), na.rm = TRUE)
} else {
  data$acc_mag <- NA_real_
}

  
  # --- Clean-up --------------------------------------------------------
  # Drop temporary timestamp column before returning
  data$.__ts <- NULL
  return(data)
  
}
```

## Function to use if main function results in error

This fallback version is a more flexible “salvage” reader for corrupted or oddly formatted UPAS files. Unlike the main function, it manually reads the file line-by-line after the header, rebuilds the log body from raw text, and aligns columns even when counts don’t match. It skips strict parsing steps (like removing problematic rows) in favor of keeping as much data as possible. In short, this one prioritizes recovering usable data when the normal read function fails due to formatting issues.

```{r,echo = FALSE,warning = FALSE, message = FALSE}
#Function if functions above result in an error
function_read_UPAS_data_error <- function(filepath) {
  # (optional) encoding guess
  enc_guess <- readr::guess_encoding(filepath)
  enc <- enc_guess$encoding[1]; if (is.na(enc)) enc <- "UTF-8"

  # parameters block
  data_parameter <- read.csv(
    filepath, header = FALSE, nrows = 76, skip = 1,
    fileEncoding = enc
  )
  colnames(data_parameter) <- c("PARAMETER", "VALUE", "UNITS.NOTES")

  # ---- read the column header row for the log body (THIS WAS MISSING) ----
  upas_colnames <- read.csv(
    filepath, header = FALSE, nrows = 1, skip = 117,
    fileEncoding = enc
  )

  # ---- salvage the log body lines ----
con <- file(filepath, "r")
on.exit(close(con), add = TRUE)

# read all lines, starting after header (~119)
all_lines <- readLines(con, warn = FALSE)
body_lines <- all_lines[120:length(all_lines)]

# join lines into a single CSV-like string
csv_text <- paste(body_lines, collapse = "\n")

# read as a normal CSV (with the same encoding)
data_raw <- suppressWarnings(
  readr::read_csv(
    csv_text,
    col_names = FALSE,
    show_col_types = FALSE,
    locale = readr::locale(encoding = enc)
  )
)

  # apply column names and type-convert
  # Ensure matching number of columns
if (ncol(data_raw) != ncol(upas_colnames)) {
  warning("Column count mismatch: attempting to align by truncation/padding")
  length_diff <- ncol(upas_colnames) - ncol(data_raw)
  if (length_diff > 0) {
    # pad with NAs if too few columns
    data_raw[(ncol(data_raw) + 1):ncol(upas_colnames)] <- NA
  } else {
    # truncate if too many columns
    data_raw <- data_raw[1:ncol(upas_colnames)]
  }
}
colnames(data_raw) <- upas_colnames[1, ]



  data_raw <- readr::type_convert(
    data_raw, locale = readr::locale(encoding = enc), na = c("", "NA")
  )

  # assemble data with header parameters
  data <- data_raw %>%
    dplyr::mutate(
      UPASserial = subset(data_parameter, PARAMETER == "UPASserial")$VALUE[1],
      SampleName = subset(data_parameter, PARAMETER == "SampleName")$VALUE[1],
      UPASexpRev = subset(data_parameter, PARAMETER == "UPASexpRev")$VALUE[1],
      CartridgeID = subset(data_parameter, PARAMETER == "CartridgeID")$VALUE[1],
      LifetimeSampleCount = subset(data_parameter, PARAMETER == "LifetimeSampleCount")$VALUE[1],
      LifetimeSampleRuntime = subset(data_parameter, PARAMETER == "LifetimeSampleRuntime")$VALUE[1],
      LifetimeBatteryRuntime = subset(data_parameter, PARAMETER == "LifetimeBatteryRuntime")$VALUE[1],
      LifetimeSamplePumptime = subset(data_parameter, PARAMETER == "LifetimeSamplePumptime")$VALUE[1],
      SampledVolume = readr::parse_number(subset(data_parameter, PARAMETER == "SampledVolumeOffset")$VALUE[1]),
      OverallDuration = subset(data_parameter, PARAMETER == "OverallDuration")$VALUE[1],
      PumpingDuration = subset(data_parameter, PARAMETER == "PumpingDuration")$VALUE[1],
      StartBatteryCharge = subset(data_parameter, PARAMETER == "StartBatteryCharge")$VALUE[1],
      EndBatteryCharge = subset(data_parameter, PARAMETER == "EndBatteryCharge")$VALUE[1],
      StartBatteryVoltage = subset(data_parameter, PARAMETER == "StartBatteryVoltage")$VALUE[1],
      EndBatteryVoltage = subset(data_parameter, PARAMETER == "EndBatteryVoltage")$VALUE[1],
      ShutdownMode = subset(data_parameter, PARAMETER == "ShutdownMode")$VALUE[1],
      DutyCycle  = subset(data_parameter, PARAMETER == "FlowDutyCycle")$VALUE[1],
      UPAS_Compliance = subset(data_parameter, PARAMETER == "PercentTimeWorn")$VALUE[1],
      PMSensorInterval = subset(data_parameter, PARAMETER == "PMSensorInterval")$VALUE[1],
      FlowOffset = subset(data_parameter, PARAMETER == "FlowOffset")$VALUE[1]
    )

  # ---- DERIVED FEATURES (movement, LUX) ----
  ts <- suppressWarnings(lubridate::ymd_hms(data$DateTimeLocal, tz = "UTC"))
  if (all(is.na(ts)) && "UnixTime" %in% names(data)) {
    ts <- as.POSIXct(as.numeric(data$UnixTime),
                     origin = "1970-01-01",
                     tz = "UTC")
  }
  data$.__ts <- ts
  
  numify <- function(x)
    suppressWarnings(readr::parse_number(as.character(x)))
  for (v in c("AccelXVar",
              "AccelYVar",
              "AccelZVar",
              "AccelComplianceCnt",
              "LUX",
              "DutyCycle")) {
    if (v %in% names(data))
      data[[v]] <- numify(data[[v]])
  }
  
  data <- data %>%
    arrange(.__ts) %>%
    mutate(
      LUX_s = zoo::rollmedian(LUX, 3, fill = NA),
      seg_sec = derive_seg_sec(.__ts, PMSensorInterval)
    )
  
  # --- Motion-based compliance -----------------------------------------
  # Convert firmware 0–20 count to proportion (0–1)
  data$AccelComplianceCnt_prop <- data$AccelComplianceCnt / 20
  
  # Boolean "worn" indicator directly from firmware logic
  data$worn_flag <- as.integer(data$AccelComplianceCnt > 0)
  
  # Keep AccelXVar sum for QC plotting only
  if (all(c("AccelXVar", "AccelYVar", "AccelZVar") %in% names(data))) {
  data$acc_mag <- rowSums(cbind(data$AccelXVar, data$AccelYVar, data$AccelZVar), na.rm = TRUE)
} else {
  data$acc_mag <- NA_real_
}

  
  # --- Clean-up --------------------------------------------------------
  data$.__ts <- NULL
  return(data)
}

```


# DOWNLOAD THE DATA 

This section loops through all UPAS files, reading and cleaning each one automatically.  

For every file, it first tries to read using the main `function_read_UPAS_data_()` (the standard parser).  
If that fails, it switches to the fallback `function_read_UPAS_data_error()` to recover data from files with formatting or encoding issues.  

Each dataset is then tagged with metadata (filter ID, subject ID, community, file name), timestamps are standardized to UTC, and elapsed time between consecutive measurements is calculated.  

The cleaned outputs are stored in a list called `list.upas`, ready for merging and analysis.

```{r,echo = FALSE,warning = FALSE, message = FALSE}
#### Create loop to load and clean all the data
list.upas <- list()

#Loop through each file in each folder
for(i in 1:length(file_upas)){

  tryCatch({
    
    filepath_upas <- file.path(path,dirname(file_upas[[i]]), basename(file_upas[i]))
    
  encoding <- guess_encoding(filepath_upas)
  function_file <- function_read_UPAS_data_(filepath_upas) 

  list.upas[[i]] <- function_file %>% 
    mutate(filter_id   = str_extract(file_upas[i], "KHU[0-9]{4}"),
      subject_id  =  str_extract(file_upas[i], "BM[0-9]{4}[M,C]{1}"),
      community =  tolower(str_extract(dirname(file_upas)[i], "[^_]+")), 
      file = file_upas[i],
      timestamp = as.POSIXct(DateTimeLocal, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"),
      timestamp = as.POSIXct(ifelse(is.na(timestamp),as.POSIXct(DateTimeLocal, format = "%Y-%m-%dT%H:%M:%S", tz = "UTC"),timestamp), format = "%Y-%m-%d %H:%M:%S", tz = "UTC") ,
      elapsed_time = difftime(timestamp, lag(timestamp), units="secs")) 
    
    
  }, error = function(e){
    
  print(paste0("Trying to process using second function for: ", basename(file_upas[i])))
    
  encoding <- guess_encoding(filepath_upas)
  function_file <- function_read_UPAS_data_error(filepath_upas) 

  list.upas[[i]] <- function_file %>% 
    mutate(filter_id   =  str_extract(file_upas[i], "KHU[0-9]{4}"),
      subject_id  = str_extract(file_upas[i], "BM[0-9]{4}[M,C]{1}"),
      community = tolower(str_extract(dirname(file_upas)[i], "[^_]+")), #NA, 
      file = file_upas[i],
      timestamp = as.POSIXct(DateTimeLocal, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"),
      timestamp = as.POSIXct(ifelse(is.na(timestamp),as.POSIXct(DateTimeLocal, format = "%Y-%m-%dT%H:%M:%S", tz = "UTC"),timestamp), format = "%Y-%m-%d %H:%M:%S", tz = "UTC") ,
      elapsed_time = difftime(timestamp, lag(timestamp), units="secs")) 
    
  })}

```

## DATA CLEANING

This section standardizes and cleans the raw UPAS data across all files.  

It first converts all numeric-like columns (e.g., PM₂.₅, flow rates, acceleration variables) to numeric values to handle any mixed or character inputs.  

Next, it checks key measurement columns for corruption—any values that don’t look like valid numbers are set to `NA`, and corresponding “_clean” columns are created for each.  

Different column sets are used depending on the firmware version (newer devices include `PumpingFlowRate`).  
These steps ensure that each dataset has consistent numeric formatting and clearly marks problematic or unreadable entries for downstream analysis.


```{r,echo = FALSE,warning = FALSE, message = FALSE}
##Pull out corrupted rows and set to null, create new column (corrupt) to indicate such
# column_debugging <- c("FilterDP","AtmoT","AtmoRH", "PM2_5MC","MassFlow","PumpingFlowRate")

#Updated columns with new firmware (Use if processing files post-May 2025 in devices with updated firmware)

column_debugging <- c("FilterDP","AtmoT","AtmoRH", "PM2_5MC","MassFlowFactory","PumpingFlowFactory", "PumpingFlowRate")

#Updated columns for August (which didn't have PumpingFlowRate)
column_debugging <- c("FilterDP", "AtmoT", "AtmoRH", "PM2_5MC", "MassFlowFactory", "PumpingFlowFactory")

numeric_like <- c(
  "PumpingDuration","PumpingFlowFactory","PumpingFlowRate",
  "PM2_5MC", "MassFlowFactory",
  "AccelComplianceCnt","StepCount",
  "AccelXVar","AccelYVar","AccelZVar",
  "XDown","Zup","Zdown","LUX"
)


for (i in seq_along(list.upas)) {
  for (col in numeric_like) {
    if (col %in% names(list.upas[[i]])) {
      # Force coercion to numeric
      list.upas[[i]][[col]] <- readr::parse_number(
        as.character(list.upas[[i]][[col]]),
        na = c("", "NA")
      )
    }
  }
}

for(i in 1:length(list.upas)){

 for (col in column_debugging)  {
   tryCatch({list.upas[[i]][,paste0(col,"_clean")] <- ifelse(grepl("^[0-9\\.]+$", as.data.frame(list.upas[[i]])[,col]) == TRUE, as.data.frame(list.upas[[i]])[,col], NA)
       }, error = function(e){print("Error computing.")})
 }}


# 
# for(i in 1:length(list.upas)){
#   for (col in column_debugging)  {
#     tryCatch({
#       if (col %in% names(list.upas[[i]])) {
#         list.upas[[i]][, paste0(col,"_clean")] <- ifelse(
#           grepl("^[0-9\\.]+$", list.upas[[i]][[col]]),
#           list.upas[[i]][[col]],
#           NA
#         )
#       } else {
#         message(paste("Column", col, "missing in file", file_upas[i]))
#       }
#     }, error = function(e){
#       message(paste("Error computing column", col, "for file", file_upas[i], ":", e$message))
#     })
#   }
# }
```

# Save as rds file

```{r,echo = FALSE,warning = FALSE, message = FALSE}
write_rds(
  list.upas,
  here::here("weekly_data_checks", "upas_data2025", "processed", paste0("list.upas_", community, date, ".rds"))
)
```


## CREATE SUMMARY DF FROM THE FULL DATA

This section initializes an empty summary data frame (`pm_summary_upas`) to hold key statistics and metadata for each UPAS run.  

It sets up standardized columns for identifiers (UPAS ID, subject, filter, community), sampling times and durations, battery and flow parameters, environmental conditions (temperature, RH, filter differential pressure), and PM 2.5 summary metrics (min, mean, max, median).  


```{r,echo = FALSE,warning = FALSE, message = FALSE}
list.upasr3_new <- list.upas

pm_summary_upas <- data.frame(
  upas_id = rep(NA, length(list.upasr3_new)),
  subject_id = rep(NA, length(list.upasr3_new)),
  duplicate_subject= rep(NA, length(list.upasr3_new)),
  # duplicate_filter_3um = rep(NA, length(list.upasr3_new)),
  filter_id = rep(NA, length(list.upasr3_new)),
  community =  rep(NA, length(list.upasr3_new)),
  start_time = rep(NA, length(list.upasr3_new)),
  end_time = rep(NA, length(list.upasr3_new)),
  run_time_hour = rep(NA, length(list.upasr3_new)),
  # run_time_hour_comp = rep(NA, length(list.upasr3_new)),
  shutdownmode = rep(NA, length(list.upasr3_new)),
  LifetimeSampleRuntime = rep(NA, length(list.upasr3_new)),
  LifetimeBatteryRuntime = rep(NA, length(list.upasr3_new)),
  LifetimeSamplePumptime = rep(NA, length(list.upasr3_new)),
  battvolt_start = rep(NA, length(list.upasr3_new)),
  battvolt_end = rep(NA, length(list.upasr3_new)),
  flowoffset = rep(NA, length(list.upasr3_new)),
  sampleVolume = rep(NA, length(list.upasr3_new)),
  pm_min = rep(NA, length(list.upasr3_new)),
  pm_max = rep(NA, length(list.upasr3_new)),
  pm_median = rep(NA, length(list.upasr3_new)),
  pm_mean = rep(NA, length(list.upasr3_new)),
  temp_min = rep(NA, length(list.upasr3_new)),
  temp_mean = rep(NA, length(list.upasr3_new)),
  temp_max = rep(NA, length(list.upasr3_new)),
  rh_min = rep(NA, length(list.upasr3_new)),
  rh_max = rep(NA, length(list.upasr3_new)),
  battery_start = rep(NA, length(list.upasr3_new)),
  battery_end = rep(NA, length(list.upasr3_new)),
  filterdp_min = rep(NA, length(list.upasr3_new)),
  filterdp_mean = rep(NA, length(list.upasr3_new)),
  filterdp_max = rep(NA, length(list.upasr3_new)),
  flow_min = rep(NA, length(list.upasr3_new)),
  flow_max = rep(NA, length(list.upasr3_new)),
  flow_mean = rep(NA, length(list.upasr3_new)),
  compliance_hours = rep(NA, length(list.upasr3_new)),
  compliance_percent = rep(NA, length(list.upasr3_new)),
  # compliance_hours_daytime = rep(NA, length(list.upasr3_new)),
  # compliance_hours_nighttime = rep(NA, length(list.upasr3_new)),
  compliance_hours_day_session1  = rep(NA, length(list.upasr3_new)),
  compliance_hours_night_session1  = rep(NA, length(list.upasr3_new)),
  compliance_hours_day_session2 = rep(NA, length(list.upasr3_new)),
  compliance_hours_night_session2 = rep(NA, length(list.upasr3_new)),
  file = rep(NA, length(list.upasr3_new))
  # badrows = rep(NA, length(list.upasr3_new))
)

#Shutdown Mode: (0=unknown error shutdown 1=user pushbutton sample stop 2=depleted battery shutdown [<2.6v] 3=successfully completed preset sample duration 4=thermal protection shutdown 5=max power at initialization error 6=max pump voltage during sample shutdown 7=blocked flow during sample shutdown 8=SD card removed during sample 64+=freeze 80+=RTOS crash)
```

## Summarize results

This section compiles key performance and quality metrics for each UPAS run into the `pm_summary_upas` data frame.  

It first defines helper functions for safely calculating run-time, compliance, and overlap within time windows (e.g., day vs. night). Then, for each UPAS file, it extracts and cleans core variables, standardizes timestamps, and derives indicators like temperature, humidity, flow, and PM₂.₅ statistics (min, mean, median, max). It also classifies shutdown modes, computes battery and flow diagnostics, and quantifies compliance hours by session (day/night, first and second 24-hour periods). 

The results are written to a CSV for use in weekly device performance checks.

```{r,echo = FALSE,warning = FALSE, message = FALSE}
## FUNCTIONS ADDED

## Calculate total hours within a given time window where mask == TRUE
hours_in_window <- function(df, mask, t0, t1) {
  if (nrow(df) == 0) return(0)
  # start/end of each row’s interval
  seg_start <- df$DateTimeLocal
  seg_end   <- df$DateTimeLocal + df$seg_sec

  # seconds of overlap with [t0, t1]
  overlap <- pmax(0, as.numeric(pmin(seg_end, t1) - pmax(seg_start, t0)))
  round(sum(overlap[mask %in% TRUE], na.rm = TRUE) / 3600, 2)
}


# Calculate total minutes during a run where mask == TRUE (capped at run_end)
minutes_in_run <- function(df, mask, run_end) {
  if (nrow(df) == 0) return(0)
  # clip each row's segment to the run window end
  eff <- pmax(0, pmin(df$seg_sec, as.numeric(run_end - df$DateTimeLocal)))
  sum(eff[mask %in% TRUE], na.rm = TRUE) / 60
}


# Safe statistic wrapper (returns NA if no finite values)
safe_stat <- function(x, fun) {
  x <- x[is.finite(x)]
  if (length(x)) fun(x, na.rm = TRUE) else NA_real_
}

# Day/night classifiers (5am–9pm = day)
is_day   <- function(t) lubridate::hour(t) >= 5 & lubridate::hour(t) < 21
is_night <- function(t) !is_day(t)
  
# ---------------------- Loop through each cleaned UPAS dataset --------------------------
for (i in 1:length(list.upasr3_new)) {
  tryCatch({
    ## get date info
    list.upasr3_new[[i]]$DateTimeLocal <- as.POSIXct(list.upasr3_new[[i]]$DateTimeLocal, format = "%Y-%m-%dT%H:%M:%S")
    list.upasr3_new[[i]]$hour = lubridate::hour(list.upasr3_new[[i]]$DateTimeLocal)
    
    # ensure chronological
    list.upasr3_new[[i]] <- list.upasr3_new[[i]][order(list.upasr3_new[[i]]$DateTimeLocal), ]
    
    # pull key header data ----
    list.upasr3_new[[i]]$PM2_5MC_clean <- as.numeric(list.upasr3_new[[i]]$PM2_5MC_clean)
    list.upasr3_new[[i]]$AtmoRH_clean <- as.numeric(list.upasr3_new[[i]]$AtmoRH_clean)
    list.upasr3_new[[i]]$AtmoT_clean <- as.numeric(list.upasr3_new[[i]]$AtmoT_clean)
    list.upasr3_new[[i]]$PumpingFlowFactory_clean <- as.numeric(list.upasr3_new[[i]]$PumpingFlowFactory_clean) # was PumpingFlowRate_clean 
    list.upasr3_new[[i]]$BattVolt <- as.numeric(list.upasr3_new[[i]]$BattVolt)
    list.upasr3_new[[i]]$FlowOffset <- as.numeric(list.upasr3_new[[i]]$FlowOffset)
    list.upasr3_new[[i]]$FilterDP_clean <- as.numeric(list.upasr3_new[[i]]$FilterDP_clean)
    list.upasr3_new[[i]]$ShutdownMode_num <- as.numeric(list.upasr3_new[[i]]$ShutdownMode)
    
        # Create a descriptive shutdown mode label
    list.upasr3_new[[i]]$ShutdownModecat <- ifelse(
      list.upasr3_new[[i]]$ShutdownMode_num == 0,
      "Unknown error shutdown",
      ifelse(
        list.upasr3_new[[i]]$ShutdownMode_num == 1,
        "User PushButton Sample Stop",
        ifelse(
          list.upasr3_new[[i]]$ShutdownMode_num == 2,
          "Depleted Battery Shutdown",
          ifelse(
            list.upasr3_new[[i]]$ShutdownMode_num == 3,
            "Sucessfully completed deployment",
            ifelse(
              list.upasr3_new[[i]]$ShutdownMode_num == 4,
              "Thermal Protection Shutdown",
              ifelse(
                list.upasr3_new[[i]]$ShutdownMode_num == 5,
                "Max power at initialization error",
                ifelse(
                  list.upasr3_new[[i]]$ShutdownMode_num == 6,
                  "Max pump voltage during sample shutdown",
                  ifelse(
                    list.upasr3_new[[i]]$ShutdownMode_num == 7,
                    "Blocked flow during shutdown",
                    ifelse(
                      list.upasr3_new[[i]]$ShutdownMode_num == 8,
                      "SD card removed during sample",
                      ifelse(
                        list.upasr3_new[[i]]$ShutdownMode_num >= 60, #Above 60 : Flag to Contact ATS for support in red
                        "Contact ATS for Support",
                        list.upasr3_new[[i]]$ShutdownMode
                      ))))))))))
    
  # ---- Populate metadata columns in the summary df ----
  pm_summary_upas$upas_id[i] <- list.upasr3_new[[i]]$UPASserial[1]
  pm_summary_upas$subject_id[i] <- list.upasr3_new[[i]]$subject_id[1]
  pm_summary_upas$duplicate_subject[i] <- ifelse(str_extract(list.upasr3_new[[i]]$SampleName[1], "DUP") == "DUP" | str_extract(list.upasr3_new[[i]]$CartridgeID[1], "DUP") == "DUP", "Yes","No")
  # pm_summary_upas$duplicate_filter_3um[i] <- ifelse( == "DUP", "Yes","No")
  pm_summary_upas$filter_id[i] <- list.upasr3_new[[i]]$filter_id[1]
  pm_summary_upas$community[i] <- list.upasr3_new[[i]]$community[1]
  pm_summary_upas$start_time[i] <- list.upasr3_new[[i]]$DateTimeLocal[1]
  #as.Date(list.upasr3_new[[i]]$DateTimeLocal[1])
  pm_summary_upas$end_time[i] <-  list.upasr3_new[[i]]$DateTimeLocal[nrow(list.upasr3_new[[i]])] #as.Date(list.upasr3_new[[i]]$DateTimeLocal[nrow(list.upasr3_new[[i]])])
  pm_summary_upas$run_time_hour[i] <-  unique(as.numeric(list.upasr3_new[[i]]$OverallDuration))
  # pm_summary_upas$run_time_hour_comp[i] <-  round(nrow(list.upasr3_new[[i]])/2/60,2)
  pm_summary_upas$shutdownmode[i] <-  list.upasr3_new[[i]]$ShutdownModecat[1]

  # ## NEW LIFETIME VARS
  pm_summary_upas$LifetimeSampleRuntime[i] <- as.numeric(trimws(list.upasr3_new[[i]]$LifetimeSampleRuntime[1]))
  pm_summary_upas$LifetimeBatteryRuntime[i] <- as.numeric(trimws(list.upasr3_new[[i]]$LifetimeBatteryRuntime[1]))
  pm_summary_upas$LifetimeSamplePumptime[i] <- as.numeric(trimws(list.upasr3_new[[i]]$LifetimeSamplePumptime[1]))

  pm_summary_upas$sampleVolume[i] <-  unique(as.numeric(list.upasr3_new[[i]]$SampledVolume))
  pm_summary_upas$battvolt_start[i] =list.upasr3_new[[i]]$BattVolt[1]
  pm_summary_upas$battvolt_end[i] =list.upasr3_new[[i]]$BattVolt[nrow(list.upasr3_new[[i]])]

  
  # ADD
  # ensure seg_sec exists; if missing or all non-finite, derive it using the same helper
if (!("seg_sec" %in% names(list.upasr3_new[[i]])) ||
    !any(is.finite(list.upasr3_new[[i]]$seg_sec))) {
  list.upasr3_new[[i]]$seg_sec <- derive_seg_sec(
    list.upasr3_new[[i]]$DateTimeLocal,
    list.upasr3_new[[i]]$PMSensorInterval
  )
}

  

  
  # ADD WEAR/COMPLIANCE FLAG ----
  if (!("worn_flag" %in% names(list.upasr3_new[[i]]))) {
    if ("AccelComplianceCnt" %in% names(list.upasr3_new[[i]])) {
      list.upasr3_new[[i]]$worn_flag <- as.integer(list.upasr3_new[[i]]$AccelComplianceCnt > 0)
    } else {
      list.upasr3_new[[i]]$worn_flag <- NA
    }
  }
  list.upasr3_new[[i]]$worn_flag <- as.logical(list.upasr3_new[[i]]$worn_flag)
  
  if ("AccelComplianceCnt" %in% names(list.upasr3_new[[i]])) {
    list.upasr3_new[[i]]$compliance_prop <- list.upasr3_new[[i]]$AccelComplianceCnt / 20
  }

  
  # --- ADD:  DEFINE THE IN RUN WINDOW ---
  run_start <- min(list.upasr3_new[[i]]$DateTimeLocal, na.rm = TRUE)
  run_end   <- run_start + pm_summary_upas$run_time_hour[i] * 3600
  
  in_run <- list.upasr3_new[[i]]$DateTimeLocal <= run_end
  
  # Two 24-hour sessions for compliance summaries
  s1_start <- run_start
  s1_end   <- min(run_end, run_start + 24 * 3600)
  
  s2_start <- s1_end
  s2_end   <- min(run_end, run_start + 48 * 3600)
  
  df <- list.upasr3_new[[i]] # RENAME TO DF FOR EASE ******
  
  # Day/night masks for session splits
  day_mask   <- is_day(df$DateTimeLocal)
  night_mask <- is_night(df$DateTimeLocal)
  
  # Effective seconds within run window
  eff <- pmax(0, pmin(df$seg_sec, as.numeric(run_end - df$DateTimeLocal))) ## eff is the effective seconds credited for each row (0 if after run_end)
  
  # Total compliance time (based on worn flag)
  wear_secs  <- sum(eff[df$worn_flag %in% TRUE], na.rm = TRUE)
  total_secs <- sum(eff, na.rm = TRUE)
  
  pm_summary_upas$compliance_hours[i]   <- round(wear_secs / 3600, 2)
  
  if (total_secs > 0) {
    pm_summary_upas$compliance_percent[i] <- round(100 * wear_secs / total_secs, 2)
  } else {
    pm_summary_upas$compliance_percent[i] <- NA_real_
  }
  
  
  
  ## ----- IN RUN STATS --------
  df_inrun <- df[in_run, ]
  df_inrun$PM2_5MC_clean <- as.numeric(df_inrun$PM2_5MC_clean)
  
  df_inrun <- df[in_run, ] %>%
    arrange(DateTimeLocal) %>%
    mutate(PM2_5MC_filled = zoo::na.locf(PM2_5MC_clean, na.rm = FALSE))
  
  # PM stats (corrected for PM every 15 minute idiosyncrasy)
  pm_summary_upas$pm_min[i]    <- round(safe_stat(df_inrun$PM2_5MC_clean, min), 2)
  pm_summary_upas$pm_max[i]    <- round(safe_stat(df_inrun$PM2_5MC_clean, max), 2)
  pm_summary_upas$pm_mean[i]   <- round(mean(df_inrun$PM2_5MC_filled, na.rm = TRUE), 2)
  pm_summary_upas$pm_median[i] <- round(median(df_inrun$PM2_5MC_filled, na.rm = TRUE), 2)
  
  # Temperature (in-run)
  pm_summary_upas$temp_min[i]  <- round(safe_stat(df$AtmoT_clean[in_run], min), 2)
  pm_summary_upas$temp_mean[i] <- round(safe_stat(df$AtmoT_clean[in_run], mean), 2)
  pm_summary_upas$temp_max[i]  <- round(safe_stat(df$AtmoT_clean[in_run], max), 2)
  
  # RH (in-run)
  pm_summary_upas$rh_min[i]    <- round(safe_stat(df$AtmoRH_clean[in_run], min), 2)
  pm_summary_upas$rh_max[i]    <- round(safe_stat(df$AtmoRH_clean[in_run], max), 2)
  
  # Filter ΔP (in-run)
  pm_summary_upas$filterdp_min[i]  <- round(safe_stat(df$FilterDP_clean[in_run], min), 2)
  pm_summary_upas$filterdp_mean[i] <- round(safe_stat(df$FilterDP_clean[in_run], mean), 2)
  pm_summary_upas$filterdp_max[i]  <- round(safe_stat(df$FilterDP_clean[in_run], max), 2)
  
  # Flow (in-run)
  pm_summary_upas$flow_min[i]   <- round(safe_stat(df$PumpingFlowFactory_clean[in_run], min), 2)
  pm_summary_upas$flow_mean[i]  <- round(safe_stat(df$PumpingFlowFactory_clean[in_run], mean), 2)
  pm_summary_upas$flow_max[i]   <- round(safe_stat(df$PumpingFlowFactory_clean[in_run], max), 2)
  
  # Flow offset (in-run)
  pm_summary_upas$flowoffset[i] <- round(safe_stat(df$FlowOffset[in_run], mean), 2)
  

  # BATTERY START/END WITHIN THE IN-RUN WINDOW
  ix <- which(in_run)
  if (length(ix)) {
    pm_summary_upas$battery_start[i] <- df$BatteryCharge[min(ix)]
    pm_summary_upas$battery_end[i]   <- df$BatteryCharge[max(ix)]
  } else {
    pm_summary_upas$battery_start[i] <- NA
    pm_summary_upas$battery_end[i]   <- NA
  }
  
  
  ## TEMPERATURE FLAG SET UP ---
  # minutes with ambient T > 50°C during the run (seg_sec-weighted, clipped at run_end)
  pm_summary_upas$temp_minutes_over_50[i] <-
    round(
      minutes_in_run(
        list.upasr3_new[[i]],
        is.finite(list.upasr3_new[[i]]$AtmoT_clean) &
          list.upasr3_new[[i]]$AtmoT_clean > 50,
        run_end
      ),
      1
    )
  
  temp_max_in_run <- suppressWarnings(max(list.upasr3_new[[i]]$AtmoT_clean[in_run], na.rm = TRUE))
  
  pm_summary_upas$temp_max_flag_over_53[i] <- as.integer(is.finite(temp_max_in_run) &&
                                                           temp_max_in_run > 53)

  # FLOW FLAG SET UP --- 
  # minutes with flow < 0.9 during the run (seg_sec-weighted, clipped)
  pm_summary_upas$flow_minutes_under_0_9[i] <-
    round(
      minutes_in_run(
        list.upasr3_new[[i]],
        is.finite(list.upasr3_new[[i]]$PumpingFlowFactory_clean) &
          list.upasr3_new[[i]]$PumpingFlowFactory_clean < 0.9,
        run_end
      ),
      1
    )
  pm_summary_upas$flow_flag_low[i] <- as.integer(pm_summary_upas$flow_minutes_under_0_9[i] > 10)

  
  
  ## Day/Night compliance by sessions (0–24 h, 24–48 h) -----------------------
  
  pm_summary_upas$compliance_hours_day_session1[i]   <- hours_in_window(df, df$worn_flag & day_mask,   s1_start, s1_end)
  pm_summary_upas$compliance_hours_night_session1[i] <- hours_in_window(df, df$worn_flag & night_mask, s1_start, s1_end)
  pm_summary_upas$compliance_hours_day_session2[i]   <- hours_in_window(df, df$worn_flag & day_mask,   s2_start, s2_end)
  pm_summary_upas$compliance_hours_night_session2[i] <- hours_in_window(df, df$worn_flag & night_mask, s2_start, s2_end)
  

  # ADD THE FILE NAME
  pm_summary_upas$file[i] <- list.upasr3_new[[i]]$file[1]
  # pm_summary_upas$badrows[i] <- list.upasr3_new[[i]]$badrows[1]
  
  },

error = function(e) {
  message("Error processing index ", i, ": ", conditionMessage(e))
})
  
}

# ADD THE COMMUNITY
pm_summary_upas$community <- community 

#Save summary as csv file

write.csv(pm_summary_upas, here::here("weekly_data_checks", "upas_data2025", "processed", paste0("pm_summary_upas_", community, date, ".csv")))
```


## Save output as excel file with conditional formatting

This section exports the summarized UPAS data to a formatted Excel workbook for easy review.  
A new sheet is created for each community/date combination, and conditional formatting rules are applied to highlight potential issues:  

Red cells flag suspect values (e.g., short run times, negative PM or temperature readings, extreme temperatures or RH, abnormal flow rates). Compliance metrics are highlighted when day or night wear hours are too low. Flags also identify temperature over 50 °C, low flow periods, duplicate samples, and problematic shutdown modes.  

The result is a clear, color-coded Excel report (`formatted_[community]_[date].xlsx`) that makes quality control checks quick and visual.

```{r}
library(openxlsx)

# Create workbook
wb <- createWorkbook()
sheet_name <- paste0(community, "_", date)
addWorksheet(wb, sheet_name)


writeData(wb, sheet_name, pm_summary_upas)


rows <- 2:(nrow(pm_summary_upas) + 1)  # header is row 1
style_red <- createStyle(bgFill = "red")

# Helper to get column index
get_col <- function(var) which(names(pm_summary_upas) == var)

# Conditional formatting rules
apply_rules <- function(var, rule, type = "expression") {
  if (var %in% names(pm_summary_upas)) {
    conditionalFormatting(wb, sheet_name, cols = get_col(var), rows = rows, rule = rule, style = style_red, type = type)
  }
}

# Add all rules
purrr::walk(c("run_time_hour"), ~apply_rules(.x, "<=44"))
purrr::walk(c("pm_max", "pm_median", "pm_mean", "temp_min", "rh_min"), ~apply_rules(.x, "<0"))
purrr::walk(c("temp_max", "temp_mean"), ~apply_rules(.x, ">45"))
apply_rules("rh_max", ">99")
purrr::walk(c("flow_max", "flow_mean"), ~apply_rules(.x, ">2.08"))
apply_rules("flow_mean", "<0.96")
purrr::walk(c("compliance_hours_day_session1", "compliance_hours_day_session2"), ~apply_rules(.x, "<=10"))
purrr::walk(c("compliance_hours_night_session1", "compliance_hours_night_session2"), ~apply_rules(.x, "<1"))
apply_rules("temp_minutes_over_50", ">0")
apply_rules("flow_minutes_under_0_9", ">10")
purrr::walk(c("temp_max_flag_over_53", "flow_flag_low"), ~apply_rules(.x, "==1"))

# Text match rules
if ("duplicate_subject" %in% names(pm_summary_upas)) {
  conditionalFormatting(wb, sheet_name, cols = get_col("duplicate_subject"), rows = rows, type = "contains", rule = "Yes", style = style_red)
}
if ("shutdownmode" %in% names(pm_summary_upas)) {
  conditionalFormatting(wb, sheet_name, cols = get_col("shutdownmode"), rows = rows, type = "contains", rule = "Contact ATS for Support", style = style_red)
}

# Save Excel file
write_path <- here::here("weekly_data_checks", "upas_data2025", "processed", paste0("formatted_", community, "_", date, ".xlsx"))
saveWorkbook(wb, write_path, overwrite = TRUE)

```


