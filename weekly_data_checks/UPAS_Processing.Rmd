---
title: "UPAS Processing"
date: "`r Sys.Date()`"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

### Load Dependancies

library(ggplot2)
library(plotly)
library(scales)
library(lubridate)
library(data.table)
library(gridExtra)
library(cowplot)
library(plyr)
library(dplyr)
library(grid)
library(zoo)
library(openxlsx)
library(beanplot)
library(readr)
library(htmlwidgets)
library(leaflet)
library(readxl)
library(xts)
library(dygraphs)
library(ggdist) #for half-density plots
library(dplyr)
library(tidyr)
library(stringr)
library(gt)
library(gtsummary)
library(astr)
library(ggpubr)
library(data.table)
library(here)

```

## Load path to specific folder containing txt files to be read and cleaned

```{r,echo = FALSE}

##Import raw UPAS files
path <- "/Users/lewiswhite/CHAP_columbia/GRAPHS/exposure_analysis/weekly_data_checks/upas_data2025/weekly_report_data/ASANTEKWA UPAS DATA_20251018"

file_upas <- list.files(path, pattern = "*.txt", full.names = F,recursive = TRUE)

length(file_upas)

# specify meta data 
date = "20251018"
community = "asantekwa"
```


## Specify column names of interest
```{r, echo = FALSE}
#Previous UPAS Firmware (Prior to May 2025)

#118 columns
upas_colnames <- c("SampleTime","UnixTime", "UnixTimeMCU","DateTimeUTC","DateTimeLocal","PumpingFlowRate" ,"OverallFlowRate","SampledVolume" , "FilterDP" ,                "BatteryCharge","AtmoT","AtmoP","AtmoRH","AtmoDensity","AtmoAlt","GPSQual","GPSlat","GPSlon","GPSalt","GPSsat" ,"GPSspeed","GPShDOP","AccelX" , "AccelXVar",               
"AccelXMin","AccelXMax","AccelY","AccelYVar","AccelYMin","AccelYMax","AccelZ","AccelZVar","AccelZMin","AccelZMax","RotX" ,"RotXVar" , "RotXMin","RotXMax","RotY",             "RotYVar" , "RotYMin","RotYMax", "RotZ" ,"RotZVar","RotZMin","RotZMax","AccelComplianceCnt","AccelComplianceHrs","Xup", "XDown", "Yup","Ydown","Zup","Zdown",                 "StepCount", "LUX","UVindex","HighVisRaw","LowVisRaw","IRRaw","UVRaw","PMMeasCnt","PM1MC","PM1MCVar","PM2_5MC","PM2_5MCVar","PM4MC" ,"PM4MCVar","PM10MC","PM10MCVar", "PM0_5NC", "PM0_5NCVar","PM1NC","PM1NCVar","PM2_5NC", "PM2_5NCVar","PM4NC","PM4NCVar","PM10NC","PM10NCVar","PMtypicalParticleSize","PMtypicalParticleSizeVar", "PM2_5SampledMass" ,"PMReadingErrorCnt","PMFanErrorCnt","PMLaserErrorCnt","PMFanSpeedWarn","PCB1T","PCB2T","FdpT","AccelT","PT100R","PCB2P", "PumpPow1","PumpPow2", "PumpV","MassFlow","MFSVout","BFGenergy","BattVolt","v3_3","v5","PumpsON","Dead","BCS1" , "BCS2","BC_NPG","FLOWCTL","GPSRT","SD_DATAW","SD_HEADW",                 "TPumpsOFF","TPumpsON","CO2" ,"SCDT","SCDRH","VOCRaw","NOXRaw"
)


```

## Helper function to define segment second intervals 

```{r}
# ---- shared helper: derive_seg_sec ----
derive_seg_sec <- function(ts_posix, pmsi = NA) {
  # ts_posix: POSIXct time vector (or something coercible)
  # pmsi: device PMSensorInterval (can be char like "30", "30 sec", etc.)
  t <- suppressWarnings(as.numeric(ts_posix))
  d <- c(NA_real_, diff(t))

  # 1) try median positive diff
  step_med <- suppressWarnings(stats::median(d[is.finite(d) & d > 0], na.rm = TRUE))

  # 2) fallback to PMSensorInterval (1..600 s), else 30
  if (!is.finite(step_med)) {
    step_guess <- suppressWarnings(readr::parse_number(pmsi[1]))
    if (!is.finite(step_guess) || step_guess < 1 || step_guess > 600) step_guess <- 30
    step_med <- step_guess
  }

  # credit rules
  d[1] <- step_med                    # first row gets the nominal step
  d[!is.finite(d) | d < 0] <- 0       # NA/negative diffs -> 0 credit
  d[d > 5 * step_med] <- step_med     # cap absurd gaps at 1 step

  # safety: ensure correct length
  if (length(d) != length(t)) d <- rep(step_med, length(t))
  d
}

```


## function to load data before may 2025
```{r,echo = FALSE,warning = FALSE, message = FALSE}
# #Firmware Prior to May 2025
# function_read_UPAS_data <- function(filepath) {
#   
#   data_parameter  <- read.csv(filepath, header = F, nrows = 76, skip = 1)
#   colnames(data_parameter) <- c("PARAMETER","VALUE","UNITS.NOTES")
#   
#   data_raw  <- read_csv(file = filepath, skip = 117, skip_empty_rows = T, col_names = FALSE,locale = readr::locale(encoding = encoding$encoding), guess_max = 10000, show_col_types = FALSE)
# 
#   problems <- problems(data_raw)
#   bad_rows <- problems$row
#   # print(bad_rows)
#   
#   colnames(data_raw) <- upas_colnames
#   # names <- data_raw[1,]
#   
#   # data_raw$badrows <- nrow(problems)
#   if(length(bad_rows) > 0){
#      data_raw <- data_raw[-c(bad_rows), ]
#     
#   }
# 
#   
#   data <- data_raw %>%
#     dplyr::mutate(
#            UPASserial = subset(data_parameter, PARAMETER == "UPASserial")$VALUE[1],
#            SampleName = subset(data_parameter, PARAMETER == "SampleName")$VALUE[1],
#            CartridgeID = subset(data_parameter, PARAMETER == "CartridgeID")$VALUE[1],
#            LifetimeSampleCount = subset(data_parameter, PARAMETER == "LifetimeSampleCount")$VALUE[1],
#            
#            LifetimeSampleRuntime = subset(data_parameter, PARAMETER == "LifetimeSampleRuntime")$VALUE[1],
#            LifetimeBatteryRuntime = subset(data_parameter, PARAMETER == "LifetimeBatteryRuntime")$VALUE[1],
#            LifetimeSamplePumptime = subset(data_parameter, PARAMETER == "LifetimeSamplePumptime")$VALUE[1],
#            
#            SampledVolume = readr::parse_number(subset(data_parameter, PARAMETER == "SampledVolumeOffset")$VALUE[1]),
#            
#            OverallDuration = subset(data_parameter, PARAMETER == "OverallDuration")$VALUE[1],
#            PumpingDuration = subset(data_parameter, PARAMETER == "PumpingDuration")$VALUE[1],
#            StartBatteryCharge = subset(data_parameter, PARAMETER == "StartBatteryCharge")$VALUE[1],
#            EndBatteryCharge = subset(data_parameter, PARAMETER == "EndBatteryCharge")$VALUE[1],
#            StartBatteryVoltage = subset(data_parameter, PARAMETER == "StartBatteryVoltage")$VALUE[1],
#            EndBatteryVoltage = subset(data_parameter, PARAMETER == "EndBatteryVoltage")$VALUE[1],
#            ShutdownMode = subset(data_parameter, PARAMETER == "ShutdownMode")$VALUE[1],
#            DutyCycle  = subset(data_parameter, PARAMETER == "FlowDutyCycle")$VALUE[1],
#            UPAS_Compliance = subset(data_parameter, PARAMETER == "PercentTimeWorn")$VALUE[1],
#            ShutdownMode = subset(data_parameter, PARAMETER == "ShutdownMode")$VALUE[1]  ,
#            PMSensorInterval = subset(data_parameter, PARAMETER == "PMSensorInterval")$VALUE[1] ,
#            FlowOffset = subset(data_parameter, PARAMETER == "FlowOffset")$VALUE[1] ,
#            compliance = ifelse((AccelXVar > 100) | (AccelYVar > 100) | (AccelZVar > 100), 1, 0))
# 
# 
#   data$compliance_rollmean <- ifelse(as.numeric(rollapply(data$compliance, width=20,  FUN = mean, align = "center", na.rm = TRUE, partial=F, fill = NA)) > 0, 1, 0)
#   
#   return(data)
# }
# 
# # ##Updated Firmware (May 2025 onward)
# # function_read_UPAS_data_ <- function(filepath) {
# #   
# #   data_parameter  <- read.csv(filepath, header = F, nrows = 83, skip = 1)
# #   colnames(data_parameter) <- c("PARAMETER","VALUE","UNITS.NOTES")
# #   
# #   data_raw  <- read_csv(file = filepath, skip = 119, skip_empty_rows = T, col_names = FALSE, guess_max = 10000, show_col_types = FALSE) #updated firmware*
# #   #Removed the following: locale = readr::locale(encoding = encoding$encoding)
# # 
# #   problems <- problems(data_raw)
# #   bad_rows <- problems$row
# #   
# #   #104 columns
# #   upas_colnames <-  read.csv(filepath, header = F, nrows = 1, skip = 117)
# #   colnames(data_raw) <- upas_colnames[1,]
# # 
# #   data_raw$badrows <- nrow(problems)
# # 
# #   data <- data_raw %>%
# #     dplyr::mutate(
# #            UPASserial = subset(data_parameter, PARAMETER == "UPASserial")$VALUE[1],
# #            SampleName = subset(data_parameter, PARAMETER == "SampleName")$VALUE[1],
# #            CartridgeID = subset(data_parameter, PARAMETER == "CartridgeID")$VALUE[1],
# #            LifetimeSampleCount = subset(data_parameter, PARAMETER == "LifetimeSampleCount")$VALUE[1],
# #            
# #            LifetimeSampleRuntime = subset(data_parameter, PARAMETER == "LifetimeSampleRuntime")$VALUE[1],
# #            LifetimeBatteryRuntime = subset(data_parameter, PARAMETER == "LifetimeBatteryRuntime")$VALUE[1],
# #            LifetimeSamplePumptime = subset(data_parameter, PARAMETER == "LifetimeSamplePumptime")$VALUE[1],
# #            
# #            SampledVolume = subset(data_parameter, PARAMETER == "SampledVolume")$VALUE[1],
# #            OverallDuration = subset(data_parameter, PARAMETER == "OverallDuration")$VALUE[1],
# #            PumpingDuration = subset(data_parameter, PARAMETER == "PumpingDuration")$VALUE[1],
# #            StartBatteryCharge = subset(data_parameter, PARAMETER == "StartBatteryCharge")$VALUE[1],
# #            EndBatteryCharge = subset(data_parameter, PARAMETER == "EndBatteryCharge")$VALUE[1],
# #            StartBatteryVoltage = subset(data_parameter, PARAMETER == "StartBatteryVoltage")$VALUE[1],
# #            EndBatteryVoltage = subset(data_parameter, PARAMETER == "EndBatteryVoltage")$VALUE[1],
# #            ShutdownMode = subset(data_parameter, PARAMETER == "ShutdownMode")$VALUE[1],
# #            DutyCycle  = subset(data_parameter, PARAMETER == "FlowDutyCycle")$VALUE[1],
# #            UPAS_Compliance = subset(data_parameter, PARAMETER == "PercentTimeWorn")$VALUE[1],
# #            ShutdownMode = subset(data_parameter, PARAMETER == "ShutdownMode")$VALUE[1]  ,
# #            PMSensorInterval = subset(data_parameter, PARAMETER == "PMSensorInterval")$VALUE[1] ,
# #            FlowOffset = subset(data_parameter, PARAMETER == "FlowOffset")$VALUE[1] ,
# #            compliance = ifelse((AccelXVar > 100) | (AccelYVar > 100) | (AccelZVar > 100), 1, 0))
# # 
# # 
# #   data$compliance_rollmean <- ifelse(as.numeric(rollapply(data$compliance, width=20,  FUN = mean, align = "center", na.rm = TRUE, partial=F, fill = NA)) > 0, 1, 0)
# #   
# #   return(data)
# # }


```

## funciton to load data after may 2025
```{r,echo = FALSE,warning = FALSE, message = FALSE}
function_read_UPAS_data_ <- function(filepath) {
  # 1) Detect encoding once
  enc_guess <- readr::guess_encoding(filepath)
  enc <- enc_guess$encoding[1]
  if (is.na(enc))
    enc <- "UTF-8"  # safe default
  
  # 2) Parameters block (same as before, but respect encoding)
  data_parameter <- read.csv(
    filepath,
    header = FALSE,
    nrows = 83,
    skip = 1,
    fileEncoding = enc
  )
  colnames(data_parameter) <- c("PARAMETER", "VALUE", "UNITS.NOTES")
  
  # 3) Read the header row with the same encoding
  upas_colnames <- read.csv(
    filepath,
    header = FALSE,
    nrows = 1,
    skip = 117,
    fileEncoding = enc
  )
  
  # 4) Read the log body with the same encoding
  data_raw <- readr::read_csv(
    file = filepath,
    skip = 119,
    # updated firmware
    skip_empty_rows = TRUE,
    col_names = FALSE,
    guess_max = 10000,
    show_col_types = FALSE,
    locale = readr::locale(encoding = enc)  # <-- key line
  )
  
  # 5) Apply column names
  colnames(data_raw) <- upas_colnames[1, ]
  
  # 6) Let readr repair types now that encoding is correct
  data_raw <- readr::type_convert(data_raw,
                                  locale = readr::locale(encoding = enc),
                                  na = c("", "NA"))
  
  # 7)  drop rows with parse problems
  pb <- readr::problems(data_raw)
  if (nrow(pb)) {
    bad_rows <- unique(pb$row)
    data_raw <- data_raw[-bad_rows, , drop = FALSE]
  }
  
  # 8) Get head level data 
  data <- data_raw %>%
    dplyr::mutate(
      UPASserial = subset(data_parameter, PARAMETER == "UPASserial")$VALUE[1],
      SampleName = subset(data_parameter, PARAMETER == "SampleName")$VALUE[1],
      UPASexpRev = subset(data_parameter, PARAMETER == "UPASexpRev")$VALUE[1],
      ## NEW ADD
      CartridgeID = subset(data_parameter, PARAMETER == "CartridgeID")$VALUE[1],
      LifetimeSampleCount = subset(data_parameter, PARAMETER == "LifetimeSampleCount")$VALUE[1],
      LifetimeSampleRuntime = subset(data_parameter, PARAMETER == "LifetimeSampleRuntime")$VALUE[1],
      LifetimeBatteryRuntime = subset(data_parameter, PARAMETER == "LifetimeBatteryRuntime")$VALUE[1],
      LifetimeSamplePumptime = subset(data_parameter, PARAMETER == "LifetimeSamplePumptime")$VALUE[1],
      SampledVolume = readr::parse_number(subset(data_parameter, PARAMETER == "SampledVolumeOffset")$VALUE[1]),
      
      OverallDuration = subset(data_parameter, PARAMETER == "OverallDuration")$VALUE[1],
      PumpingDuration = subset(data_parameter, PARAMETER == "PumpingDuration")$VALUE[1],
      StartBatteryCharge = subset(data_parameter, PARAMETER == "StartBatteryCharge")$VALUE[1],
      EndBatteryCharge = subset(data_parameter, PARAMETER == "EndBatteryCharge")$VALUE[1],
      StartBatteryVoltage = subset(data_parameter, PARAMETER == "StartBatteryVoltage")$VALUE[1],
      EndBatteryVoltage = subset(data_parameter, PARAMETER == "EndBatteryVoltage")$VALUE[1],
      DutyCycle  = subset(data_parameter, PARAMETER == "FlowDutyCycle")$VALUE[1],
      UPAS_Compliance = subset(data_parameter, PARAMETER == "PercentTimeWorn")$VALUE[1],
      ShutdownMode = subset(data_parameter, PARAMETER == "ShutdownMode")$VALUE[1],
      PMSensorInterval = subset(data_parameter, PARAMETER == "PMSensorInterval")$VALUE[1],
      FlowOffset = subset(data_parameter, PARAMETER == "FlowOffset")$VALUE[1]
      #compliance = ifelse((AccelXVar > 100) | (AccelYVar > 100) | (AccelZVar > 100), 1, 0)
    )
  
  # data$compliance_rollmean <- ifelse(
  #   as.numeric(zoo::rollapply(data$compliance, width = 20, FUN = mean,
  #                             align = "center", na.rm = TRUE, partial = FALSE, fill = NA)) > 0, 1, 0)
  
  
  
  # ---- DERIVED FEATURES (movement proportion, posture, lux) ----
  # robust time vector for ordering & window length
  ts <- suppressWarnings(lubridate::ymd_hms(data$DateTimeLocal, tz = "UTC"))
  if (all(is.na(ts)) && "UnixTime" %in% names(data)) {
    ts <- as.POSIXct(as.numeric(data$UnixTime),
                     origin = "1970-01-01",
                     tz = "UTC")
  }
  data$.__ts <- ts  # temp; safe even if timestamp is added later upstream
  
  # make sure the few fields we need are numeric (some files come in as chr)
  numify <- function(x)
    suppressWarnings(readr::parse_number(as.character(x)))
  for (v in c(
    "AccelXVar",
    "AccelYVar",
    "AccelZVar",
    "AccelComplianceCnt",
    "StepCount",
    "XDown",
    "Zup",
    "Zdown",
    "LUX",
    "DutyCycle"
  )) {
    if (v %in% names(data))
      data[[v]] <- numify(data[[v]])
  }
  
  
  data <- data %>%
    arrange(.__ts) %>%                           # order by time
    mutate(
      moving_30s = as.integer((AccelXVar > 100) |
                                (AccelYVar > 100) |
                                (AccelZVar > 100)),
      x_vest     = XDown / 100,
      # 0..1
      z_bed      = pmax(Zup, Zdown, na.rm = TRUE) / 100,
      LUX_s      = zoo::rollmedian(LUX, 3, fill = NA)
    )
  
  data$seg_sec <- derive_seg_sec(data$.__ts, data$PMSensorInterval)
  
  # window length ≈ 10 min based on actual interval
  dt_sec <- stats::median(diff(as.numeric(data$.__ts)), na.rm = TRUE)
  if (!is.finite(dt_sec))
    dt_sec <- 30
  k <- max(1, round((10 * 60) / dt_sec))
  
  have_cnt  <- "AccelComplianceCnt" %in% names(data) &&
    any(is.finite(data$AccelComplianceCnt))
  have_step <- "StepCount" %in% names(data)          &&
    any(is.finite(data$StepCount))
  rev       <- if ("UPASexpRev" %in% names(data))
    data$UPASexpRev[1]
  else
    NA_character_
  duty_num  <- suppressWarnings(as.numeric(data$DutyCycle[1]))
  
  # choose source per manual
  if (isTRUE(duty_num == 100) &&
      !identical(rev, "0BR2") && have_step) {
    data$movement_prop10m <- zoo::rollapply(
      as.integer(data$StepCount > 0),
      k,
      mean,
      align = "right",
      partial = FALSE,
      fill = NA
    )
  } else if (!isTRUE(duty_num == 100) &&
             !identical(rev, "0BR2") && have_cnt) {
    data$movement_prop10m <- data$AccelComplianceCnt / 20
  } else if (have_cnt) {
    data$movement_prop10m <- data$AccelComplianceCnt / 20
  } else {
    data$movement_prop10m <- zoo::rollapply(
      data$moving_30s,
      k,
      mean,
      align = "right",
      partial = FALSE,
      fill = NA
    )
  }
  
  # simple posture-based worn/not-worn (kept for plotting / context)
  data$worn_any <- (data$x_vest >= 0.6) | (data$z_bed >= 0.6)

  # --- stricter wearing flag: orientation AND recent movement -------------
  # choose a binary movement source (same priority as for movement_prop10m)
  base_move_bin <- if (isTRUE(duty_num == 100) && !identical(rev, "0BR2") && have_step) {
    as.integer(data$StepCount > 0)
  } else if (have_cnt) {
    as.integer(data$AccelComplianceCnt > 0)
  } else {
    data$moving_30s
  }

  # window defining "recent" movement (last 30 min)
  dt_sec <- stats::median(diff(as.numeric(data$.__ts)), na.rm = TRUE)
  if (!is.finite(dt_sec)) dt_sec <- 30
  k_alive <- max(1, round((30 * 60) / dt_sec))

  # any movement in the last 30 min?
  data$move_recent30m <- zoo::rollapply(
    base_move_bin, k_alive, max,
    align = "right", partial = TRUE, fill = 0
  )

  # strict wearing definition
  data$worn_flag <- ((data$x_vest >= 0.6) | (data$z_bed >= 0.6)) & (data$move_recent30m == 1)

  # keep the raw 30s motion flag for QC
  data$compliance_flag_30s <- data$moving_30s
  
  # drop temp time
  data$.__ts <- NULL
  
  return(data)
}
```

## Function to use if main function results in error

```{r,echo = FALSE,warning = FALSE, message = FALSE}
#Function if functions above result in an error
function_read_UPAS_data_error <- function(filepath) {
  # (optional) encoding guess
  enc_guess <- readr::guess_encoding(filepath)
  enc <- enc_guess$encoding[1]; if (is.na(enc)) enc <- "UTF-8"

  # parameters block
  data_parameter <- read.csv(
    filepath, header = FALSE, nrows = 76, skip = 1,
    fileEncoding = enc
  )
  colnames(data_parameter) <- c("PARAMETER", "VALUE", "UNITS.NOTES")

  # ---- read the column header row for the log body (THIS WAS MISSING) ----
  upas_colnames <- read.csv(
    filepath, header = FALSE, nrows = 1, skip = 117,
    fileEncoding = enc
  )

  # ---- salvage the log body lines ----
  con <- file(filepath, "r")
  on.exit(close(con), add = TRUE)
  valid_lines <- character()   # <-- must initialize; you had this commented out
  line_counter <- 0

  while (length(line <- readLines(con, n = 1, warn = FALSE)) > 0) {
    line_counter <- line_counter + 1
    if (line_counter < 116) next
    tryCatch({
      readr::read_csv(I(line), col_names = FALSE, show_col_types = FALSE,
                      locale = readr::locale(encoding = enc))
      valid_lines <- c(valid_lines, line)
    }, error = function(e) {
      message("Skipping invalid line: ", line)
    })
  }

  # combine salvaged lines
  data_raw <- readr::read_csv(
    paste(valid_lines, collapse = "\n"),
    col_names = FALSE,
    show_col_types = FALSE,
    locale = readr::locale(encoding = enc)
  )

  # apply column names and type-convert
  colnames(data_raw) <- upas_colnames[1, ]
  data_raw <- readr::type_convert(
    data_raw, locale = readr::locale(encoding = enc), na = c("", "NA")
  )

  # assemble data with header parameters
  data <- data_raw %>%
    dplyr::mutate(
      UPASserial = subset(data_parameter, PARAMETER == "UPASserial")$VALUE[1],
      SampleName = subset(data_parameter, PARAMETER == "SampleName")$VALUE[1],
      UPASexpRev = subset(data_parameter, PARAMETER == "UPASexpRev")$VALUE[1],
      CartridgeID = subset(data_parameter, PARAMETER == "CartridgeID")$VALUE[1],
      LifetimeSampleCount = subset(data_parameter, PARAMETER == "LifetimeSampleCount")$VALUE[1],
      LifetimeSampleRuntime = subset(data_parameter, PARAMETER == "LifetimeSampleRuntime")$VALUE[1],
      LifetimeBatteryRuntime = subset(data_parameter, PARAMETER == "LifetimeBatteryRuntime")$VALUE[1],
      LifetimeSamplePumptime = subset(data_parameter, PARAMETER == "LifetimeSamplePumptime")$VALUE[1],
      SampledVolume = readr::parse_number(subset(data_parameter, PARAMETER == "SampledVolumeOffset")$VALUE[1]),
      OverallDuration = subset(data_parameter, PARAMETER == "OverallDuration")$VALUE[1],
      PumpingDuration = subset(data_parameter, PARAMETER == "PumpingDuration")$VALUE[1],
      StartBatteryCharge = subset(data_parameter, PARAMETER == "StartBatteryCharge")$VALUE[1],
      EndBatteryCharge = subset(data_parameter, PARAMETER == "EndBatteryCharge")$VALUE[1],
      StartBatteryVoltage = subset(data_parameter, PARAMETER == "StartBatteryVoltage")$VALUE[1],
      EndBatteryVoltage = subset(data_parameter, PARAMETER == "EndBatteryVoltage")$VALUE[1],
      ShutdownMode = subset(data_parameter, PARAMETER == "ShutdownMode")$VALUE[1],
      DutyCycle  = subset(data_parameter, PARAMETER == "FlowDutyCycle")$VALUE[1],
      UPAS_Compliance = subset(data_parameter, PARAMETER == "PercentTimeWorn")$VALUE[1],
      PMSensorInterval = subset(data_parameter, PARAMETER == "PMSensorInterval")$VALUE[1],
      FlowOffset = subset(data_parameter, PARAMETER == "FlowOffset")$VALUE[1]
    )

  # robust time vector
  ts <- suppressWarnings(lubridate::ymd_hms(data$DateTimeLocal, tz = "UTC"))
  if (all(is.na(ts)) && "UnixTime" %in% names(data)) {
    ts <- as.POSIXct(as.numeric(data$UnixTime), origin = "1970-01-01", tz = "UTC")
  }
  data$.__ts <- ts

  # force numerics where needed
  numify <- function(x) suppressWarnings(readr::parse_number(as.character(x)))
  for (v in c("AccelXVar","AccelYVar","AccelZVar","AccelComplianceCnt","StepCount",
              "XDown","Zup","Zdown","LUX","DutyCycle")) {
    if (v %in% names(data)) data[[v]] <- numify(data[[v]])
  }

  data <- data %>%
    arrange(.__ts) %>%
    mutate(
      moving_30s = as.integer((AccelXVar > 100) | (AccelYVar > 100) | (AccelZVar > 100)),
      x_vest     = XDown / 100,
      z_bed      = pmax(Zup, Zdown, na.rm = TRUE) / 100,
      LUX_s      = zoo::rollmedian(LUX, 3, fill = NA)
    )

  # --- seg_sec using the shared helper ---
  data$seg_sec <- derive_seg_sec(data$.__ts, data$PMSensorInterval)

  # window len for 10-min roll
  dt_sec <- stats::median(diff(as.numeric(data$.__ts)), na.rm = TRUE)
  if (!is.finite(dt_sec)) dt_sec <- 30
  k <- max(1, round((10 * 60) / dt_sec))

  have_cnt  <- "AccelComplianceCnt" %in% names(data) && any(is.finite(data$AccelComplianceCnt))
  have_step <- "StepCount" %in% names(data) && any(is.finite(data$StepCount))
  rev       <- if ("UPASexpRev" %in% names(data)) data$UPASexpRev[1] else NA_character_
  duty_num  <- suppressWarnings(as.numeric(data$DutyCycle[1]))

  if (isTRUE(duty_num == 100) && !identical(rev, "0BR2") && have_step) {
    data$movement_prop10m <- zoo::rollapply(as.integer(data$StepCount > 0),
                                            k, mean, align = "right",
                                            partial = FALSE, fill = NA)
  } else if (!isTRUE(duty_num == 100) && !identical(rev, "0BR2") && have_cnt) {
    data$movement_prop10m <- data$AccelComplianceCnt / 20
  } else if (have_cnt) {
    data$movement_prop10m <- data$AccelComplianceCnt / 20
  } else {
    data$movement_prop10m <- zoo::rollapply(data$moving_30s,
                                            k, mean, align = "right",
                                            partial = FALSE, fill = NA)
  }

  # simple posture-based worn/not-worn (kept for plotting / context)
  data$worn_any <- (data$x_vest >= 0.6) | (data$z_bed >= 0.6)

  # --- stricter wearing flag: orientation AND recent movement -------------
  # choose a binary movement source (same priority as for movement_prop10m)
  base_move_bin <- if (isTRUE(duty_num == 100) && !identical(rev, "0BR2") && have_step) {
    as.integer(data$StepCount > 0)
  } else if (have_cnt) {
    as.integer(data$AccelComplianceCnt > 0)
  } else {
    data$moving_30s
  }

  # window defining "recent" movement (last 30 min)
  dt_sec <- stats::median(diff(as.numeric(data$.__ts)), na.rm = TRUE)
  if (!is.finite(dt_sec)) dt_sec <- 30
  k_alive <- max(1, round((30 * 60) / dt_sec))

  # any movement in the last 30 min?
  data$move_recent30m <- zoo::rollapply(
    base_move_bin, k_alive, max,
    align = "right", partial = TRUE, fill = 0
  )

  # strict wearing definition
  data$worn_flag <- ((data$x_vest >= 0.6) | (data$z_bed >= 0.6)) & (data$move_recent30m == 1)

  # keep the raw 30s motion flag for QC
  data$compliance_flag_30s <- data$moving_30s
  
  data$.__ts <- NULL

  return(data)
}

```


# DOWNLOAD THE DATA 

```{r,echo = FALSE,warning = FALSE, message = FALSE}
#### Create loop to load and clean all the data
list.upas <- list()

#Loop through each file in each folder
for(i in 1:length(file_upas)){

  tryCatch({
    
    filepath_upas <- file.path(path,dirname(file_upas[[i]]), basename(file_upas[i]))
    
  encoding <- guess_encoding(filepath_upas)
  function_file <- function_read_UPAS_data_(filepath_upas) 

  list.upas[[i]] <- function_file %>% 
    mutate(filter_id   = str_extract(file_upas[i], "KHU[0-9]{4}"),
      subject_id  =  str_extract(file_upas[i], "BM[0-9]{4}[M,C]{1}"),
      community =  tolower(str_extract(dirname(file_upas)[i], "[^_]+")), 
      file = file_upas[i],
      timestamp = as.POSIXct(DateTimeLocal, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"),
      timestamp = as.POSIXct(ifelse(is.na(timestamp),as.POSIXct(DateTimeLocal, format = "%Y-%m-%dT%H:%M:%S", tz = "UTC"),timestamp), format = "%Y-%m-%d %H:%M:%S", tz = "UTC") ,
      elapsed_time = difftime(timestamp, lag(timestamp), units="secs")) 
    
    
  }, error = function(e){
    
  print(paste0("Trying to process using second function for: ", basename(file_upas[i])))
    
  encoding <- guess_encoding(filepath_upas)
  function_file <- function_read_UPAS_data_error(filepath_upas) 

  list.upas[[i]] <- function_file %>% 
    mutate(filter_id   =  str_extract(file_upas[i], "KHU[0-9]{4}"),
      subject_id  = str_extract(file_upas[i], "BM[0-9]{4}[M,C]{1}"),
      community = tolower(str_extract(dirname(file_upas)[i], "[^_]+")), #NA, 
      file = file_upas[i],
      timestamp = as.POSIXct(DateTimeLocal, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"),
      timestamp = as.POSIXct(ifelse(is.na(timestamp),as.POSIXct(DateTimeLocal, format = "%Y-%m-%dT%H:%M:%S", tz = "UTC"),timestamp), format = "%Y-%m-%d %H:%M:%S", tz = "UTC") ,
      elapsed_time = difftime(timestamp, lag(timestamp), units="secs")) 
    
  })}

```

## DATA CLEANING

```{r,echo = FALSE,warning = FALSE, message = FALSE}


##Pull out corrupted rows and set to null, create new column (corrupt) to indicate such
# column_debugging <- c("FilterDP","AtmoT","AtmoRH", "PM2_5MC","MassFlow","PumpingFlowRate")

#Updated columns with new firmware (Use if processing files post-May 2025 in devices with updated firmware)

column_debugging <- c("FilterDP","AtmoT","AtmoRH", "PM2_5MC","MassFlowFactory","PumpingFlowFactory", "PumpingFlowRate")

#Updated columns for August (which didn't have PumpingFlowRate)
column_debugging <- c("FilterDP", "AtmoT", "AtmoRH", "PM2_5MC", "MassFlowFactory", "PumpingFlowFactory")

numeric_like <- c(
  "PumpingDuration","PumpingFlowFactory","PumpingFlowRate",
  "PM2_5MC",
  "AccelComplianceCnt","StepCount",
  "AccelXVar","AccelYVar","AccelZVar",
  "XDown","Zup","Zdown","LUX"
)


for (i in seq_along(list.upas)) {
  for (col in numeric_like) {
    if (col %in% names(list.upas[[i]])) {
      # Force coercion to numeric
      list.upas[[i]][[col]] <- readr::parse_number(
        as.character(list.upas[[i]][[col]]),
        na = c("", "NA")
      )
    }
  }
}

for(i in 1:length(list.upas)){

 for (col in column_debugging)  {
   tryCatch({list.upas[[i]][,paste0(col,"_clean")] <- ifelse(grepl("^[0-9\\.]+$", as.data.frame(list.upas[[i]])[,col]) == TRUE, as.data.frame(list.upas[[i]])[,col], NA)
       }, error = function(e){print("Error computing.")})
 }}


# 
# for(i in 1:length(list.upas)){
#   for (col in column_debugging)  {
#     tryCatch({
#       if (col %in% names(list.upas[[i]])) {
#         list.upas[[i]][, paste0(col,"_clean")] <- ifelse(
#           grepl("^[0-9\\.]+$", list.upas[[i]][[col]]),
#           list.upas[[i]][[col]],
#           NA
#         )
#       } else {
#         message(paste("Column", col, "missing in file", file_upas[i]))
#       }
#     }, error = function(e){
#       message(paste("Error computing column", col, "for file", file_upas[i], ":", e$message))
#     })
#   }
# }
```

# Save as rds file

```{r,echo = FALSE,warning = FALSE, message = FALSE}

write_rds(
  list.upas,
  here::here("weekly_data_checks", "upas_data2025", "processed", paste0("list.upas_", community, date, ".rds"))
)
```


## CREATE SUMMARY DF FROM THE FULL DATA

### initialize empty df
```{r,echo = FALSE,warning = FALSE, message = FALSE}
list.upasr3_new <- list.upas

pm_summary_upas <- data.frame(
  upas_id = rep(NA, length(list.upasr3_new)),
  subject_id = rep(NA, length(list.upasr3_new)),
  duplicate_subject= rep(NA, length(list.upasr3_new)),
  # duplicate_filter_3um = rep(NA, length(list.upasr3_new)),
  filter_id = rep(NA, length(list.upasr3_new)),
  community =  rep(NA, length(list.upasr3_new)),
  start_time = rep(NA, length(list.upasr3_new)),
  end_time = rep(NA, length(list.upasr3_new)),
  run_time_hour = rep(NA, length(list.upasr3_new)),
  # run_time_hour_comp = rep(NA, length(list.upasr3_new)),
  shutdownmode = rep(NA, length(list.upasr3_new)),
  LifetimeSampleRuntime = rep(NA, length(list.upasr3_new)),
  LifetimeBatteryRuntime = rep(NA, length(list.upasr3_new)),
  LifetimeSamplePumptime = rep(NA, length(list.upasr3_new)),
  battvolt_start = rep(NA, length(list.upasr3_new)),
  battvolt_end = rep(NA, length(list.upasr3_new)),
  flowoffset = rep(NA, length(list.upasr3_new)),
  sampleVolume = rep(NA, length(list.upasr3_new)),
  pm_min = rep(NA, length(list.upasr3_new)),
  pm_max = rep(NA, length(list.upasr3_new)),
  pm_median = rep(NA, length(list.upasr3_new)),
  pm_mean = rep(NA, length(list.upasr3_new)),
  temp_min = rep(NA, length(list.upasr3_new)),
  temp_mean = rep(NA, length(list.upasr3_new)),
  temp_max = rep(NA, length(list.upasr3_new)),
  rh_min = rep(NA, length(list.upasr3_new)),
  rh_max = rep(NA, length(list.upasr3_new)),
  battery_start = rep(NA, length(list.upasr3_new)),
  battery_end = rep(NA, length(list.upasr3_new)),
  filterdp_min = rep(NA, length(list.upasr3_new)),
  filterdp_mean = rep(NA, length(list.upasr3_new)),
  filterdp_max = rep(NA, length(list.upasr3_new)),
  flow_min = rep(NA, length(list.upasr3_new)),
  flow_max = rep(NA, length(list.upasr3_new)),
  flow_mean = rep(NA, length(list.upasr3_new)),
  compliance_hours = rep(NA, length(list.upasr3_new)),
  compliance_percent = rep(NA, length(list.upasr3_new)),
  # compliance_hours_daytime = rep(NA, length(list.upasr3_new)),
  # compliance_hours_nighttime = rep(NA, length(list.upasr3_new)),
  compliance_hours_day_session1  = rep(NA, length(list.upasr3_new)),
  compliance_hours_night_session1  = rep(NA, length(list.upasr3_new)),
  compliance_hours_day_session2 = rep(NA, length(list.upasr3_new)),
  compliance_hours_night_session2 = rep(NA, length(list.upasr3_new)),
  file = rep(NA, length(list.upasr3_new))
  # badrows = rep(NA, length(list.upasr3_new))
)

#Shutdown Mode: (0=unknown error shutdown 1=user pushbutton sample stop 2=depleted battery shutdown [<2.6v] 3=successfully completed preset sample duration 4=thermal protection shutdown 5=max power at initialization error 6=max pump voltage during sample shutdown 7=blocked flow during sample shutdown 8=SD card removed during sample 64+=freeze 80+=RTOS crash)
```

## Summarize results

```{r,echo = FALSE,warning = FALSE, message = FALSE}
## FUNCTIONS ADDED

# safe_hours_run <- function(df, mask, run_end) {
#   if (nrow(df) == 0) return(0)
#   eff <- pmax(0, pmin(df$seg_sec, as.numeric(run_end - df$DateTimeLocal)))
#   round(sum(eff[mask %in% TRUE], na.rm = TRUE) / 3600, 2)
#   }

# replace the old safe_hours_run with this
hours_in_window <- function(df, mask, t0, t1) {
  if (nrow(df) == 0) return(0)
  # start/end of each row’s interval
  seg_start <- df$DateTimeLocal
  seg_end   <- df$DateTimeLocal + df$seg_sec

  # seconds of overlap with [t0, t1]
  overlap <- pmax(0, as.numeric(pmin(seg_end, t1) - pmax(seg_start, t0)))
  round(sum(overlap[mask %in% TRUE], na.rm = TRUE) / 3600, 2)
}





minutes_in_run <- function(df, mask, run_end) {
  if (nrow(df) == 0) return(0)
  # clip each row's segment to the run window end
  eff <- pmax(0, pmin(df$seg_sec, as.numeric(run_end - df$DateTimeLocal)))
  sum(eff[mask %in% TRUE], na.rm = TRUE) / 60
}

safe_stat <- function(x, fun) {
  x <- x[is.finite(x)]
  if (length(x)) fun(x, na.rm = TRUE) else NA_real_
}

is_day   <- function(t) lubridate::hour(t) >= 5 & lubridate::hour(t) < 21
is_night <- function(t) !is_day(t)
  

for (i in 1:length(list.upasr3_new)) {
  tryCatch({
    ## get date info
    list.upasr3_new[[i]]$DateTimeLocal <- as.POSIXct(list.upasr3_new[[i]]$DateTimeLocal, format = "%Y-%m-%dT%H:%M:%S")
    list.upasr3_new[[i]]$hour = lubridate::hour(list.upasr3_new[[i]]$DateTimeLocal)
    
    # ensure chronological
    list.upasr3_new[[i]] <- list.upasr3_new[[i]][order(list.upasr3_new[[i]]$DateTimeLocal), ]
    
    # pull key header data ----
    list.upasr3_new[[i]]$PM2_5MC_clean <- as.numeric(list.upasr3_new[[i]]$PM2_5MC_clean)
    list.upasr3_new[[i]]$AtmoRH_clean <- as.numeric(list.upasr3_new[[i]]$AtmoRH_clean)
    list.upasr3_new[[i]]$AtmoT_clean <- as.numeric(list.upasr3_new[[i]]$AtmoT_clean)
    list.upasr3_new[[i]]$PumpingFlowFactory_clean <- as.numeric(list.upasr3_new[[i]]$PumpingFlowFactory_clean) # was PumpingFlowRate_clean 
    list.upasr3_new[[i]]$BattVolt <- as.numeric(list.upasr3_new[[i]]$BattVolt)
    list.upasr3_new[[i]]$FlowOffset <- as.numeric(list.upasr3_new[[i]]$FlowOffset)
    list.upasr3_new[[i]]$FilterDP_clean <- as.numeric(list.upasr3_new[[i]]$FilterDP_clean)
    list.upasr3_new[[i]]$ShutdownMode_num <- as.numeric(list.upasr3_new[[i]]$ShutdownMode)
    
    list.upasr3_new[[i]]$ShutdownModecat <- ifelse(
      list.upasr3_new[[i]]$ShutdownMode_num == 0,
      "Unknown error shutdown",
      ifelse(
        list.upasr3_new[[i]]$ShutdownMode_num == 1,
        "User PushButton Sample Stop",
        ifelse(
          list.upasr3_new[[i]]$ShutdownMode_num == 2,
          "Depleted Battery Shutdown",
          ifelse(
            list.upasr3_new[[i]]$ShutdownMode_num == 3,
            "Sucessfully completed deployment",
            ifelse(
              list.upasr3_new[[i]]$ShutdownMode_num == 4,
              "Thermal Protection Shutdown",
              ifelse(
                list.upasr3_new[[i]]$ShutdownMode_num == 5,
                "Max power at initialization error",
                ifelse(
                  list.upasr3_new[[i]]$ShutdownMode_num == 6,
                  "Max pump voltage during sample shutdown",
                  ifelse(
                    list.upasr3_new[[i]]$ShutdownMode_num == 7,
                    "Blocked flow during shutdown",
                    ifelse(
                      list.upasr3_new[[i]]$ShutdownMode_num == 8,
                      "SD card removed during sample",
                      ifelse(
                        list.upasr3_new[[i]]$ShutdownMode_num >= 60, #Above 60 : Flag to Contact ATS for support in red
                        "Contact ATS for Support",
                        list.upasr3_new[[i]]$ShutdownMode
                      ))))))))))
    
  
  pm_summary_upas$upas_id[i] <- list.upasr3_new[[i]]$UPASserial[1]
  pm_summary_upas$subject_id[i] <- list.upasr3_new[[i]]$subject_id[1]
  pm_summary_upas$duplicate_subject[i] <- ifelse(str_extract(list.upasr3_new[[i]]$SampleName[1], "DUP") == "DUP" | str_extract(list.upasr3_new[[i]]$CartridgeID[1], "DUP") == "DUP", "Yes","No")
  # pm_summary_upas$duplicate_filter_3um[i] <- ifelse( == "DUP", "Yes","No")
  pm_summary_upas$filter_id[i] <- list.upasr3_new[[i]]$filter_id[1]
  pm_summary_upas$community[i] <- list.upasr3_new[[i]]$community[1]
  pm_summary_upas$start_time[i] <- list.upasr3_new[[i]]$DateTimeLocal[1]
  #as.Date(list.upasr3_new[[i]]$DateTimeLocal[1])
  pm_summary_upas$end_time[i] <-  list.upasr3_new[[i]]$DateTimeLocal[nrow(list.upasr3_new[[i]])] #as.Date(list.upasr3_new[[i]]$DateTimeLocal[nrow(list.upasr3_new[[i]])])
  pm_summary_upas$run_time_hour[i] <-  unique(as.numeric(list.upasr3_new[[i]]$OverallDuration))
  # pm_summary_upas$run_time_hour_comp[i] <-  round(nrow(list.upasr3_new[[i]])/2/60,2)
  pm_summary_upas$shutdownmode[i] <-  list.upasr3_new[[i]]$ShutdownModecat[1]

  # ## NEW LIFETIME VARS
  pm_summary_upas$LifetimeSampleRuntime[i] <- as.numeric(trimws(list.upasr3_new[[i]]$LifetimeSampleRuntime[1]))
  pm_summary_upas$LifetimeBatteryRuntime[i] <- as.numeric(trimws(list.upasr3_new[[i]]$LifetimeBatteryRuntime[1]))
  pm_summary_upas$LifetimeSamplePumptime[i] <- as.numeric(trimws(list.upasr3_new[[i]]$LifetimeSamplePumptime[1]))

  pm_summary_upas$sampleVolume[i] <-  unique(as.numeric(list.upasr3_new[[i]]$SampledVolume))
  pm_summary_upas$battvolt_start[i] =list.upasr3_new[[i]]$BattVolt[1]
  pm_summary_upas$battvolt_end[i] =list.upasr3_new[[i]]$BattVolt[nrow(list.upasr3_new[[i]])]

  
  # ADD
  # ensure seg_sec exists; if missing or all non-finite, derive it using the same helper
if (!("seg_sec" %in% names(list.upasr3_new[[i]])) ||
    !any(is.finite(list.upasr3_new[[i]]$seg_sec))) {
  list.upasr3_new[[i]]$seg_sec <- derive_seg_sec(
    list.upasr3_new[[i]]$DateTimeLocal,
    list.upasr3_new[[i]]$PMSensorInterval
  )
}

  

  
  # --- ADD: WEAR FLAG BASED ON X/Y/Z UP/DOWN ---
  # --- WEAR FLAG (prefer the strict flag from the reader) ---
  if ("worn_flag" %in% names(list.upasr3_new[[i]])) {
    # already computed in the reader: orientation + recent movement
    list.upasr3_new[[i]]$worn_flag <- as.logical(list.upasr3_new[[i]]$worn_flag)
  } else if ("worn_any" %in% names(list.upasr3_new[[i]])) {
    # posture-only fallback
    list.upasr3_new[[i]]$worn_flag <- as.logical(list.upasr3_new[[i]]$worn_any)
  } else if ("movement_prop10m" %in% names(list.upasr3_new[[i]])) {
    # last fallback: movement-only threshold
    list.upasr3_new[[i]]$worn_flag <- list.upasr3_new[[i]]$movement_prop10m >= 0.05
  } else {
    list.upasr3_new[[i]]$worn_flag <- NA
  }

  
  # --- ADD:  DEFINE THE IN RUN WINDOW ---
  run_start <- min(list.upasr3_new[[i]]$DateTimeLocal, na.rm = TRUE)
  run_end   <- run_start + pm_summary_upas$run_time_hour[i] * 3600
  
  in_run <- list.upasr3_new[[i]]$DateTimeLocal <= run_end
  
  # sessions
  s1_start <- run_start
  s1_end   <- min(run_end, run_start + 24 * 3600)
  
  s2_start <- s1_end
  s2_end   <- min(run_end, run_start + 48 * 3600)
  
  df <- list.upasr3_new[[i]] # RENAME TO DF FOR EASE ******
  
  # masks
  day_mask   <- is_day(df$DateTimeLocal)
  night_mask <- is_night(df$DateTimeLocal)
  
  # Clip each row’s credited seconds to the run window 
  eff <- pmax(0, pmin(df$seg_sec, as.numeric(run_end - df$DateTimeLocal))) ## eff is the effective seconds credited for each row (0 if after run_end)
  
  ## ADD: COMPLIANCE BASED ON WORN FLAG AND EFFECTIVE SECONDS 
  wear_secs  <- sum(eff[df$worn_flag %in% TRUE], na.rm = TRUE)
  total_secs <- sum(eff, na.rm = TRUE)
  
  pm_summary_upas$compliance_hours[i]   <- round(wear_secs / 3600, 2)
  
  if (total_secs > 0) {
    pm_summary_upas$compliance_percent[i] <- round(100 * wear_secs / total_secs, 2)
  } else {
    pm_summary_upas$compliance_percent[i] <- NA_real_
  }

  
  ## ----- IN RUN STATS --------
  # PM (in-run)
  pm_summary_upas$pm_min[i]    <- round(safe_stat(df$PM2_5MC_clean[in_run], min), 2)
  pm_summary_upas$pm_median[i] <- round(safe_stat(df$PM2_5MC_clean[in_run], median), 2)
  pm_summary_upas$pm_mean[i]   <- round(safe_stat(df$PM2_5MC_clean[in_run], mean), 2)
  pm_summary_upas$pm_max[i]    <- round(safe_stat(df$PM2_5MC_clean[in_run], max), 2)
  
  # Temperature (in-run)
  pm_summary_upas$temp_min[i]  <- round(safe_stat(df$AtmoT_clean[in_run], min), 2)
  pm_summary_upas$temp_mean[i] <- round(safe_stat(df$AtmoT_clean[in_run], mean), 2)
  pm_summary_upas$temp_max[i]  <- round(safe_stat(df$AtmoT_clean[in_run], max), 2)
  
  # RH (in-run)
  pm_summary_upas$rh_min[i]    <- round(safe_stat(df$AtmoRH_clean[in_run], min), 2)
  pm_summary_upas$rh_max[i]    <- round(safe_stat(df$AtmoRH_clean[in_run], max), 2)
  
  # Filter ΔP (in-run)
  pm_summary_upas$filterdp_min[i]  <- round(safe_stat(df$FilterDP_clean[in_run], min), 2)
  pm_summary_upas$filterdp_mean[i] <- round(safe_stat(df$FilterDP_clean[in_run], mean), 2)
  pm_summary_upas$filterdp_max[i]  <- round(safe_stat(df$FilterDP_clean[in_run], max), 2)
  
  # Flow (in-run)
  pm_summary_upas$flow_min[i]   <- round(safe_stat(df$PumpingFlowFactory_clean[in_run], min), 2)
  pm_summary_upas$flow_mean[i]  <- round(safe_stat(df$PumpingFlowFactory_clean[in_run], mean), 2)
  pm_summary_upas$flow_max[i]   <- round(safe_stat(df$PumpingFlowFactory_clean[in_run], max), 2)
  
  # Flow offset (in-run)
  pm_summary_upas$flowoffset[i] <- round(safe_stat(df$FlowOffset[in_run], mean), 2)
  

  # BATTERY START/END WITHIN THE IN-RUN WINDOW
  ix <- which(in_run)
  if (length(ix)) {
    pm_summary_upas$battery_start[i] <- df$BatteryCharge[min(ix)]
    pm_summary_upas$battery_end[i]   <- df$BatteryCharge[max(ix)]
  } else {
    pm_summary_upas$battery_start[i] <- NA
    pm_summary_upas$battery_end[i]   <- NA
  }
  
  
  ## TEMPERATURE FLAG SET UP ---
  # minutes with ambient T > 50°C during the run (seg_sec-weighted, clipped at run_end)
  pm_summary_upas$temp_minutes_over_50[i] <-
    round(
      minutes_in_run(
        list.upasr3_new[[i]],
        is.finite(list.upasr3_new[[i]]$AtmoT_clean) &
          list.upasr3_new[[i]]$AtmoT_clean > 50,
        run_end
      ),
      1
    )
  
  temp_max_in_run <- suppressWarnings(max(list.upasr3_new[[i]]$AtmoT_clean[in_run], na.rm = TRUE))
  
  pm_summary_upas$temp_max_flag_over_53[i] <- as.integer(is.finite(temp_max_in_run) &&
                                                           temp_max_in_run > 53)

  # FLOW FLAG SET UP --- 
  # minutes with flow < 0.9 during the run (seg_sec-weighted, clipped)
  pm_summary_upas$flow_minutes_under_0_9[i] <-
    round(
      minutes_in_run(
        list.upasr3_new[[i]],
        is.finite(list.upasr3_new[[i]]$PumpingFlowFactory_clean) &
          list.upasr3_new[[i]]$PumpingFlowFactory_clean < 0.9,
        run_end
      ),
      1
    )
  pm_summary_upas$flow_flag_low[i] <- as.integer(pm_summary_upas$flow_minutes_under_0_9[i] > 10)

  
  
  ## Day/Night compliance by sessions (0–24 h, 24–48 h) -----------------------
  
  pm_summary_upas$compliance_hours_day_session1[i]   <- hours_in_window(df, df$worn_flag & day_mask,   s1_start, s1_end)
  pm_summary_upas$compliance_hours_night_session1[i] <- hours_in_window(df, df$worn_flag & night_mask, s1_start, s1_end)
  pm_summary_upas$compliance_hours_day_session2[i]   <- hours_in_window(df, df$worn_flag & day_mask,   s2_start, s2_end)
  pm_summary_upas$compliance_hours_night_session2[i] <- hours_in_window(df, df$worn_flag & night_mask, s2_start, s2_end)
  
  # df24hr <- subset(list.upasr3_new[[i]],
  #                      DateTimeLocal <= list.upasr3_new[[i]]$DateTimeLocal[1] + 60 * 60 * 24)
  # 
  # df_24_48hr <- subset(
  #   list.upasr3_new[[i]],
  #   DateTimeLocal >  list.upasr3_new[[i]]$DateTimeLocal[1] + 60 * 60 * 24 &
  #     DateTimeLocal <= list.upasr3_new[[i]]$DateTimeLocal[1] + 60 *
  #     60 * 48
  # )
  # 
  # pm_summary_upas$compliance_hours_day_session1[i]   <- safe_hours_run(df24hr,
  #                                                                      df24hr$worn_flag & is_day(df24hr$DateTimeLocal),
  #                                                                      run_end)
  # 
  # pm_summary_upas$compliance_hours_night_session1[i] <- safe_hours_run(df24hr,
  #                                                                      df24hr$worn_flag & is_night(df24hr$DateTimeLocal),
  #                                                                      run_end)
  # 
  # pm_summary_upas$compliance_hours_day_session2[i]   <- safe_hours_run(df_24_48hr,
  #                                                                      df_24_48hr$worn_flag & is_day(df_24_48hr$DateTimeLocal),
  #                                                                      run_end)
  # 
  # pm_summary_upas$compliance_hours_night_session2[i] <- safe_hours_run(df_24_48hr,
  #                                                                      df_24_48hr$worn_flag & is_night(df_24_48hr$DateTimeLocal),
  #                                                                      run_end)
  
  # ADD THE FILE NAME
  pm_summary_upas$file[i] <- list.upasr3_new[[i]]$file[1]
  # pm_summary_upas$badrows[i] <- list.upasr3_new[[i]]$badrows[1]
  
  },

error = function(e) {
  message("Error processing index ", i, ": ", conditionMessage(e))
})
  
}

# ADD THE COMMUNITY
pm_summary_upas$community <- community 

#Save summary as csv file

write.csv(pm_summary_upas, here::here("weekly_data_checks", "upas_data2025", "processed", paste0("pm_summary_upas_", community, date, ".csv")))
```



## Save output as excel file with conditional formatting

```{r}
library(openxlsx)

# Create workbook
wb <- createWorkbook()
sheet_name <- paste0(community, "_", date)
addWorksheet(wb, sheet_name)


writeData(wb, sheet_name, pm_summary_upas)


rows <- 2:(nrow(pm_summary_upas) + 1)  # header is row 1
style_red <- createStyle(bgFill = "red")

# Helper to get column index
get_col <- function(var) which(names(pm_summary_upas) == var)

# Conditional formatting rules
apply_rules <- function(var, rule, type = "expression") {
  if (var %in% names(pm_summary_upas)) {
    conditionalFormatting(wb, sheet_name, cols = get_col(var), rows = rows, rule = rule, style = style_red, type = type)
  }
}

# Add all rules
purrr::walk(c("run_time_hour"), ~apply_rules(.x, "<=44"))
purrr::walk(c("pm_max", "pm_median", "pm_mean", "temp_min", "rh_min"), ~apply_rules(.x, "<0"))
purrr::walk(c("temp_max", "temp_mean"), ~apply_rules(.x, ">45"))
apply_rules("rh_max", ">99")
purrr::walk(c("flow_max", "flow_mean"), ~apply_rules(.x, ">2.08"))
apply_rules("flow_mean", "<0.96")
purrr::walk(c("compliance_hours_day_session1", "compliance_hours_day_session2"), ~apply_rules(.x, "<=10"))
purrr::walk(c("compliance_hours_night_session1", "compliance_hours_night_session2"), ~apply_rules(.x, "<1"))
apply_rules("temp_minutes_over_50", ">0")
apply_rules("flow_minutes_under_0_9", ">10")
purrr::walk(c("temp_max_flag_over_53", "flow_flag_low"), ~apply_rules(.x, "==1"))

# Text match rules
if ("duplicate_subject" %in% names(pm_summary_upas)) {
  conditionalFormatting(wb, sheet_name, cols = get_col("duplicate_subject"), rows = rows, type = "contains", rule = "Yes", style = style_red)
}
if ("shutdownmode" %in% names(pm_summary_upas)) {
  conditionalFormatting(wb, sheet_name, cols = get_col("shutdownmode"), rows = rows, type = "contains", rule = "Contact ATS for Support", style = style_red)
}

# Save Excel file
write_path <- here::here("weekly_data_checks", "upas_data2025", "processed", paste0("formatted_", community, "_", date, ".xlsx"))
saveWorkbook(wb, write_path, overwrite = TRUE)

```



```{r}
# full <- read_rds("/Users/lewiswhite/CHAP_columbia/GRAPHS/exposure_analysis/weekly_data_checks/upas_data2025/processed/list.upas_sorunuase20250903.rds")
# 
# example_data <- full[[1]] 
# 
# example_data %>% select(timestamp, compliance, PM2_5MC_clean, subject_id, UPASserial)
# 

```


## PLOTS OF MOVEMENT

## Setup & helpers
```{r}
# library(scales)
# library(patchwork)
# 
# is_day   <- function(t) hour(t) >= 5 & hour(t) < 21
# is_night <- function(t) !is_day(t)
# 
# # Build night shading rectangles (21:00–24:00 and 00:00–05:00)
# night_rects <- function(tmin, tmax, tz = "UTC") {
#   d0 <- lubridate::floor_date(with_tz(tmin, tz), "day")
#   d1 <- lubridate::ceiling_date(with_tz(tmax, tz), "day")
#   days <- seq(d0, d1, by = "1 day")
#   tibble(
#     xmin = c(days + hours(21), days + hours(0)),
#     xmax = c(days + hours(24), days + hours(5)),
#     ymin = -Inf, ymax = Inf
#   ) |> filter(xmin < tmax & xmax > tmin)
# }
# 
# # If needed, quickly compute seg_sec for a df (you already do this, but just in case)
# ensure_seg_sec <- function(df){
#   if (!"seg_sec" %in% names(df)) {
#     t <- as.numeric(df$DateTimeLocal)
#     d <- c(NA_real_, diff(t))
#     step_med <- stats::median(d[is.finite(d) & d > 0], na.rm = TRUE)
#     if (!is.finite(step_med)) step_med <- 30
#     d[1] <- step_med; d[!is.finite(d)] <- 0; d[d < 0] <- 0; d[d > 5*step_med] <- step_med
#     df$seg_sec <- d
#   }
#   df
# }
# 
# # Join meta (run_time_hour) from pm_summary_upas by file
# meta_by_file <- pm_summary_upas |> select(file, subject_id, upas_id, run_time_hour)
# 
# # Convenient label for orientation “state”
# orient_state <- function(x_vest, z_bed, thr = 0.6){
#   dplyr::case_when(
#     x_vest >= thr & z_bed <  thr ~ "Vest",
#     z_bed  >= thr & x_vest <  thr ~ "Bed",
#     x_vest >= thr & z_bed  >= thr ~ "Vest+Bed",
#     TRUE                          ~ "Other"
#   )
# }
# 
# 
# night_hist_data <- function(df, run_hours, session = 1, worn_only = TRUE) {
#   stopifnot("seg_sec" %in% names(df))
#   stopifnot("worn_flag" %in% names(df))
#   stopifnot("movement_prop10m" %in% names(df))
# 
#   # window
#   run_start <- min(df$DateTimeLocal, na.rm = TRUE)
#   run_end   <- run_start + run_hours * 3600
#   s1_start <- run_start
#   s1_end   <- min(run_end, run_start + 24 * 3600)
#   s2_start <- s1_end
#   s2_end   <- min(run_end, run_start + 48 * 3600)
#   if (session == 1) { t0 <- s1_start; t1 <- s1_end } else { t0 <- s2_start; t1 <- s2_end }
# 
#   # overlap seconds with [t0, t1]
#   seg_start <- df$DateTimeLocal
#   seg_end   <- df$DateTimeLocal + df$seg_sec
#   overlap   <- pmax(0, as.numeric(pmin(seg_end, t1) - pmax(seg_start, t0)))
# 
#   # masks (vectorized)
#   night_ok  <- lubridate::hour(df$DateTimeLocal) < 5 | lubridate::hour(df$DateTimeLocal) >= 21
#   worn_ok   <- if (worn_only) (df$worn_flag %in% TRUE) else rep(TRUE, nrow(df))
# 
#   eff_sec   <- ifelse(night_ok & worn_ok, overlap, 0)
# 
#   # bin movement_prop10m to 0.1 steps
#   bks <- seq(0, 1, by = 0.1)                      # keep 0.1-wide bins (or 0.05 if you prefer)
#   mv  <- pmax(0, pmin(1, df$movement_prop10m))    # clamp to [0,1]
#   
#   # regular bins first (so we inherit the usual labels like "[0,0.1]")
#   bin_cut <- cut(mv,
#                  breaks = bks,
#                  include.lowest = TRUE,
#                  right = TRUE)
#   
#   # relabel exact zeros into their own spike without changing your downstream code
#   bin <- factor(ifelse(mv == 0, "[0]", as.character(bin_cut)), levels = c("[0]", levels(bin_cut)))
#   
#   
#   
#   suppressPackageStartupMessages({ library(dplyr); library(tidyr); library(tibble) })
# 
#   tibble(bin, seconds = eff_sec) %>%
#     filter(!is.na(bin)) %>%                                   # drop NA-movement rows
#     group_by(bin) %>%
#     summarise(minutes = sum(seconds)/60, .groups = "drop") %>%
#     complete(bin, fill = list(minutes = 0)) %>%
#     mutate(prop = if (sum(minutes) > 0) minutes / sum(minutes) else 0)
# }


```

## Plot 1 — Movement time-series (10-min prop), with day/night shading 
shows the movement time-series with day/night shading
```{r}
# plot_movement_timeseries <- function(df, run_hours, title = NULL) {
#   df <- df |>
#     mutate(
#       DateTimeLocal = as.POSIXct(DateTimeLocal, tz = "UTC"),
#       movement_prop10m = if ("movement_prop10m" %in% names(df)) movement_prop10m else NA_real_
#     ) |>
#     arrange(DateTimeLocal)
# 
#   # in-run window
#   run_start <- min(df$DateTimeLocal, na.rm = TRUE)
#   run_end   <- run_start + run_hours*3600
#   df_run    <- df |> filter(DateTimeLocal <= run_end)
# 
#   # night shading
#   rects <- night_rects(min(df_run$DateTimeLocal), max(df_run$DateTimeLocal))
# 
#   ggplot(df_run, aes(DateTimeLocal, movement_prop10m)) +
#     geom_rect(data = rects, aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),
#               inherit.aes = FALSE, alpha = 0.12) +
#     geom_line(na.rm = TRUE) +
#     scale_y_continuous(labels = percent_format(accuracy = 1), limits = c(0, 1)) +
#     labs(
#       x = NULL, y = "Movement (10-min proportion)",
#       title = title %||% "Movement over time (day/night shaded)"
#     ) +
#     theme_bw(base_size = 12)
# }

```

## Plot 2 — Orientation (XDown ≈ vest; Zup/Zdown ≈ bed) + movement magnitude

We plot x_vest and z_bed (0–1) as lines.

We add a simple “movement magnitude” trace based on summed axis variance (rescaled 0–1) for visual context.

```{r}
# plot_orientation_timeseries <- function(df, run_hours, title = NULL) {
#   df <- df |>
#     ensure_seg_sec() |>
#     mutate(
#       DateTimeLocal = as.POSIXct(DateTimeLocal, tz = "UTC"),
#       x_vest = if ("XDown" %in% names(df)) as.numeric(XDown)/100 else NA_real_,
#       z_bed  = if ("Zup"  %in% names(df) | "Zdown" %in% names(df))
#                  pmax(suppressWarnings(as.numeric(Zup)), suppressWarnings(as.numeric(Zdown)), na.rm = TRUE)/100
#                else NA_real_,
#       acc_mag = rowSums(cbind(
#                   suppressWarnings(as.numeric(AccelXVar)),
#                   suppressWarnings(as.numeric(AccelYVar)),
#                   suppressWarnings(as.numeric(AccelZVar))
#                 ), na.rm = TRUE)
#     ) |>
#     arrange(DateTimeLocal)
# 
#   # in-run window
#   run_start <- min(df$DateTimeLocal, na.rm = TRUE)
#   run_end   <- run_start + run_hours*3600
#   df_run    <- df |> filter(DateTimeLocal <= run_end)
# 
#   # rescale acc magnitude to 0..1 for plotting
#   rng <- range(df_run$acc_mag, na.rm = TRUE)
#   df_run <- df_run |>
#     mutate(acc_mag01 = if (is.finite(rng[1]) && diff(rng) > 0) (acc_mag - rng[1]) / diff(rng) else NA_real_)
# 
#   rects <- night_rects(min(df_run$DateTimeLocal), max(df_run$DateTimeLocal))
# 
#   p_orient <- ggplot(df_run, aes(DateTimeLocal)) +
#     geom_rect(data = rects, aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),
#               inherit.aes = FALSE, alpha = 0.12) +
#     geom_line(aes(y = x_vest), linewidth = 0.6) +
#     geom_line(aes(y = z_bed),  linewidth = 0.6, linetype = 2, col = "red") +
#     scale_y_continuous(labels = percent_format(accuracy = 1), limits = c(0, 1)) +
#     labs(x = NULL, y = "Orientation (proportion)",
#          subtitle = "Solid = XDown (vest); Dashed = max(Zup, Zdown) (bed)") +
#     theme_bw(base_size = 12)
# 
#   p_move <- ggplot(df_run, aes(DateTimeLocal, acc_mag01)) +
#     geom_rect(data = rects, aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf),
#               inherit.aes = FALSE, alpha = 0.12) +
#     geom_line(na.rm = TRUE) +
#     scale_y_continuous(labels = percent_format(accuracy = 1), limits = c(0, 1)) +
#     labs(x = NULL, y = "Movement magnitude (scaled 0–1)",
#          subtitle = "Sum of axis variances, rescaled") +
#     theme_bw(base_size = 12)
# 
#   (p_orient / p_move) + plot_annotation(title = title %||% "Orientation + movement context")
# }

```

## Plot 3 — Nighttime movement timing (adjacent vs. sporadic)

This summarizes minutes moving while worn across the night hours. If bars concentrate in 21:00–23:00 and ~05:00 bins, that’s “adjacent to daytime”; if spread across the 00:00–04:00 bins, that’s “sporadic overnight”.

```{r}
# plot_night_by_hour <- function(df, run_hours, title = NULL, move_thr = 0.10) {
#   df <- df |>
#     mutate(DateTimeLocal = as.POSIXct(DateTimeLocal, tz = "UTC")) |>
#     arrange(DateTimeLocal)
# 
#   run_start <- min(df$DateTimeLocal, na.rm = TRUE)
#   run_end   <- run_start + run_hours * 3600
#   df_run    <- df |> filter(DateTimeLocal <= run_end)
# 
#   # movement proxy
#   if ("movement_prop10m" %in% names(df_run)) {
#     moving <- df_run$movement_prop10m >= move_thr
#   } else if ("moving_30s" %in% names(df_run)) {
#     moving <- df_run$moving_30s == 1
#   } else {
#     moving <- rep(FALSE, nrow(df_run))
#   }
# 
#   # worn flag (no recycling)
#   worn <- if ("worn_flag" %in% names(df_run)) (df_run$worn_flag %in% TRUE) else rep(TRUE, nrow(df_run))
# 
#   # night
#   night <- lubridate::hour(df_run$DateTimeLocal) < 5 | lubridate::hour(df_run$DateTimeLocal) >= 21
# 
#   # minutes credit
#   minutes <- df_run$seg_sec / 60
# 
#   # hour-of-night ordering: 21,22,23,00,01,02,03,04,05
#   hod      <- lubridate::hour(df_run$DateTimeLocal)
#   hod_ord  <- ifelse(hod < 6, hod + 24, hod)
#   bin      <- factor(hod_ord,
#                      levels = c(21,22,23,24,25,26,27,28,29),
#                      labels = c("21","22","23","00","01","02","03","04","05"))
# 
#   library(dplyr); library(tidyr); library(tibble); library(ggplot2)
# 
#   df_sum <- tibble(bin, minutes = ifelse(night & worn & moving, minutes, 0)) |>
#     group_by(bin) |>
#     summarise(minutes = sum(minutes, na.rm = TRUE), .groups = "drop") |>
#     complete(bin, fill = list(minutes = 0))
# 
#   ggplot(df_sum, aes(bin, minutes)) +
#     geom_col() +
#     labs(x = "Hour of night", y = "Minutes moving (worn)",
#          title = title %||% "Nighttime movement by hour",
#          subtitle = "Higher bars at 21–23 or ~05 suggest adjacency to daytime; flat profile suggests sporadic night movement") +
#     theme_bw(base_size = 12)
# }
# 
# # plot_night_by_hour(df_i, run_h)
```

## Run for 1 plot

```{r}
# # pick one record to test
# i <- 5
# df <- list.upasr3_new[[i]]
# 
# # get run hours + labels from your summary for this file
# file_i <- df$file[1]
# ix     <- match(file_i, pm_summary_upas$file)
# run_h  <- as.numeric(pm_summary_upas$run_time_hour[ix])
# subj   <- pm_summary_upas$subject_id[ix]
# upas   <- pm_summary_upas$upas_id[ix]
# ttl    <- paste0(subj, " / UPAS ", upas, " — ", basename(file_i))
# 
# # make the three plots
# p1 <- plot_movement_timeseries(df, run_h, title = ttl)
# p2 <- plot_orientation_timeseries(df, run_h, title = ttl)
# p3 <- plot_night_by_hour(df, run_h, title = ttl)
# 
# # preview in the Viewer/Plots pane
# print(p1); print(p2); print(p3)
# 
# # (optional) save just these
# # ggsave("test_movement_ts.png", p1, width = 12, height = 4, dpi = 200)
# # ggsave("test_orientation_plus_movement.png", p2, width = 12, height = 6, dpi = 200)
# # ggsave("test_night_movement_hist.png", p3, width = 8, height = 4, dpi = 200)

```

PLOT 2:
* Rescaled sum = raw signal strength (continuous).
* The biggest spike of movement = 1 (100%), everything else is relative at 30s level.
* The raw variances are in arbitrary sensor units (mg²) and can be very large (hundreds to thousands). To plot them on a 0–1 scale, you typically divide by the maximum observed value in that session (or sometimes the 95th percentile to reduce the effect of outliers).




```{r}
# plot_night_movement_bins <- function(df, run_hours, session = 1, worn_only = TRUE,
#                                      y = c("prop","minutes"), title = NULL) {
#   y <- match.arg(y)
#   dat <- night_hist_data(df, run_hours, session, worn_only)
#   ggplot(dat, aes(x = bin, y = .data[[y]])) +
#     geom_col() +
#     labs(x = "10-min movement proportion bin", 
#          y = if (y == "prop") "Share of night minutes" else "Minutes",
#          title = title %||% sprintf("Night movement distribution (Session %d, %s)", 
#                                     session, if (worn_only) "worn-only" else "all-night")) +
#     theme_minimal(base_size = 12)
# }
# 
# i <- 5
# df_i <- list.upasr3_new[[i]]
# run_h <- as.numeric(pm_summary_upas$run_time_hour[match(df_i$file[1], pm_summary_upas$file)])
# plot_night_movement_bins(df_i, run_h, session = 1, worn_only = TRUE, y = "prop")

```











## Run for each file

```{r}
# Choose an output folder if you want to save


# out_dir <- here::here("weekly_data_checks", "upas_data2025", "plots")
# dir.create(out_dir, showWarnings = FALSE, recursive = TRUE)
# 
# for (i in seq_along(list.upasr3_new)) {
#   df <- list.upasr3_new[[i]]
#   file_i <- df$file[1]
#   meta   <- meta_by_file |> filter(file == file_i)
#   if (!nrow(meta)) next
# 
#   run_h <- as.numeric(meta$run_time_hour[1])
#   subj  <- meta$subject_id[1]
#   upas  <- meta$upas_id[1]
# 
#   ttl <- paste0(subj, " / UPAS ", upas, " — ", basename(file_i))
# 
#   p1 <- plot_movement_timeseries(df, run_h, title = ttl)
#   p2 <- plot_orientation_timeseries(df, run_h, title = ttl)
#   p3 <- plot_night_movement_hist(df, run_h, title = ttl)
# 
#   # Preview in RStudio:
#   # print(p1); print(p2); print(p3)
# 
#   # Save
#   ggsave(file.path(out_dir, paste0(subj, "_", upas, "_movement_ts.png")), p1, width = 12, height = 4, dpi = 200)
#   ggsave(file.path(out_dir, paste0(subj, "_", upas, "_orientation_plus_movement.png")), p2, width = 12, height = 6, dpi = 200)
#   ggsave(file.path(out_dir, paste0(subj, "_", upas, "_night_movement_hist.png")), p3, width = 8, height = 4, dpi = 200)
# }

```


Threshold for “moving” at night: move_thr = 0.10 in plot_night_movement_hist(); set to 0.05 or 0.20 to adjust sensitivity.

Orientation threshold: orient_state() and your thinking use 0.6 (60%) for “high”. You can use that to create a categorical timeline if you want a 4th plot (Vest/Bed/Other).

Day/night definition: currently 05:00–21:00 = day. Adjust in is_day() if needed.

Rounding: your summary rounds to 2 decimals; the plots show full traces, so tiny mismatches from rounding won’t matter.

